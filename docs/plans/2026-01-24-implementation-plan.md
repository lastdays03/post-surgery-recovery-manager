# ìˆ˜ìˆ  í›„ íšŒë³µ ê´€ë¦¬ ë§¤ë‹ˆì € êµ¬í˜„ ê³„íš

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**Goal:** Next.js + Supabase + OpenAI GPT-4oë¥¼ ì‚¬ìš©í•˜ì—¬ ìˆ˜ìˆ  í›„ íšŒë³µì„ ë•ëŠ” AI ê¸°ë°˜ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ êµ¬ì¶•

**Architecture:**
- í”„ë¡ íŠ¸ì—”ë“œ: Next.js 14 App Router + TypeScript + Tailwind CSS
- ë°±ì—”ë“œ: Next.js API Routes + Supabase PostgreSQL + pgvector
- AI: OpenAI GPT-4o (ì±—ë´‡, ì‹ë‹¨ ìƒì„±) + RAG (ë²¡í„° ê²€ìƒ‰)

**Tech Stack:** Next.js 14, TypeScript, Supabase, OpenAI API, Tailwind CSS, Zustand, React Hook Form, React-PDF

---

## Phase 1: í”„ë¡œì íŠ¸ ì´ˆê¸° ì„¤ì • (Foundation)

### Task 1: Next.js í”„ë¡œì íŠ¸ ì´ˆê¸°í™”

**Files:**
- Create: `package.json`
- Create: `next.config.js`
- Create: `tsconfig.json`
- Create: `tailwind.config.ts`

**Step 1: Next.js í”„ë¡œì íŠ¸ ìƒì„±**

```bash
npx create-next-app@latest . --typescript --tailwind --app --no-src-dir --import-alias "@/*"
```

Expected: í”„ë¡œì íŠ¸ êµ¬ì¡° ìƒì„± ì™„ë£Œ

**Step 2: í•„ìˆ˜ ì˜ì¡´ì„± ì„¤ì¹˜**

```bash
npm install @supabase/supabase-js@latest zustand react-hook-form @react-pdf/renderer openai zod lucide-react
npm install -D @types/node
```

**Step 3: ê°œë°œ ì„œë²„ ì‹¤í–‰ í™•ì¸**

```bash
npm run dev
```

Expected: http://localhost:3000 ì—ì„œ Next.js ê¸°ë³¸ í˜ì´ì§€ í‘œì‹œ

**Step 4: Commit**

```bash
git add .
git commit -m "chore: initialize Next.js 14 project with TypeScript and Tailwind"
```

---

### Task 2: í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±

**Files:**
- Create: `app/layout.tsx`
- Create: `app/page.tsx`
- Create: `lib/.gitkeep`
- Create: `components/.gitkeep`
- Create: `data/.gitkeep`
- Create: `public/.gitkeep`

**Step 1: ë””ë ‰í† ë¦¬ ìƒì„±**

```bash
mkdir -p app/api app/onboarding app/dashboard app/meal-plan app/exercise-plan app/symptom-check app/reports/weekly app/settings
mkdir -p lib/ai
mkdir -p components/ui
mkdir -p data/protocols data/meals data/exercises
mkdir -p public/images/exercises public/icons
mkdir -p supabase/migrations
mkdir -p scripts
```

**Step 2: .gitkeep íŒŒì¼ ìƒì„±**

```bash
touch lib/.gitkeep components/.gitkeep data/.gitkeep public/.gitkeep
```

**Step 3: í™˜ê²½ ë³€ìˆ˜ í…œí”Œë¦¿ ìƒì„±**

Create: `.env.local.example`

```bash
# Supabase
NEXT_PUBLIC_SUPABASE_URL=
NEXT_PUBLIC_SUPABASE_ANON_KEY=
SUPABASE_SERVICE_ROLE_KEY=

# OpenAI
OPENAI_API_KEY=
NEXT_PUBLIC_ENABLE_AI_CHAT=true

# App
NEXT_PUBLIC_APP_URL=http://localhost:3000

# Cost Limits
MAX_DAILY_AI_COST_PER_USER=0.50
```

**Step 4: .gitignore ì—…ë°ì´íŠ¸**

Modify: `.gitignore`

```
# ê¸°ì¡´ ë‚´ìš© ìœ ì§€
.env.local
.env*.local
```

**Step 5: Commit**

```bash
git add .
git commit -m "chore: create project directory structure"
```

---

### Task 3: Supabase í´ë¼ì´ì–¸íŠ¸ ì„¤ì •

**Files:**
- Create: `lib/supabase-client.ts`
- Create: `lib/types/database.types.ts`

**Step 1: Supabase í´ë¼ì´ì–¸íŠ¸ ìƒì„±**

Create: `lib/supabase-client.ts`

```typescript
import { createClient } from '@supabase/supabase-js'
import type { Database } from './types/database.types'

const supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL!
const supabaseAnonKey = process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!

export const supabase = createClient<Database>(supabaseUrl, supabaseAnonKey)

// ì„œë²„ ì‚¬ì´ë“œìš© (Service Role Key)
export const supabaseAdmin = createClient<Database>(
  supabaseUrl,
  process.env.SUPABASE_SERVICE_ROLE_KEY!
)
```

**Step 2: ë°ì´í„°ë² ì´ìŠ¤ íƒ€ì… ì •ì˜**

Create: `lib/types/database.types.ts`

```typescript
export type Json =
  | string
  | number
  | boolean
  | null
  | { [key: string]: Json | undefined }
  | Json[]

export interface Database {
  public: {
    Tables: {
      users: {
        Row: {
          id: string
          created_at: string
          is_anonymous: boolean
        }
        Insert: {
          id: string
          created_at?: string
          is_anonymous?: boolean
        }
        Update: {
          id?: string
          created_at?: string
          is_anonymous?: boolean
        }
      }
      user_profiles: {
        Row: {
          id: string
          user_id: string | null
          surgery_type: string
          surgery_date: string
          digestive_capacity: string
          comorbidities: string[]
          current_phase: string | null
          local_storage_key: string | null
          created_at: string
          updated_at: string
        }
        Insert: {
          id?: string
          user_id?: string | null
          surgery_type: string
          surgery_date: string
          digestive_capacity: string
          comorbidities?: string[]
          current_phase?: string | null
          local_storage_key?: string | null
          created_at?: string
          updated_at?: string
        }
        Update: {
          id?: string
          user_id?: string | null
          surgery_type?: string
          surgery_date?: string
          digestive_capacity?: string
          comorbidities?: string[]
          current_phase?: string | null
          local_storage_key?: string | null
          created_at?: string
          updated_at?: string
        }
      }
      daily_logs: {
        Row: {
          id: string
          profile_id: string
          log_date: string
          meals_completed: Json | null
          exercises_completed: Json | null
          symptoms: Json | null
          notes: string | null
          created_at: string
        }
        Insert: {
          id?: string
          profile_id: string
          log_date: string
          meals_completed?: Json | null
          exercises_completed?: Json | null
          symptoms?: Json | null
          notes?: string | null
          created_at?: string
        }
        Update: {
          id?: string
          profile_id?: string
          log_date?: string
          meals_completed?: Json | null
          exercises_completed?: Json | null
          symptoms?: Json | null
          notes?: string | null
          created_at?: string
        }
      }
    }
  }
}
```

**Step 3: Commit**

```bash
git add lib/
git commit -m "feat: add Supabase client and database types"
```

---

## Phase 2: ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜

### Task 4: Supabase ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ìƒì„±

**Files:**
- Create: `supabase/migrations/001_initial_schema.sql`

**Step 1: ì´ˆê¸° ìŠ¤í‚¤ë§ˆ ë§ˆì´ê·¸ë ˆì´ì…˜ íŒŒì¼ ì‘ì„±**

Create: `supabase/migrations/001_initial_schema.sql`

```sql
-- Users í…Œì´ë¸”
CREATE TABLE users (
  id UUID PRIMARY KEY REFERENCES auth.users(id) ON DELETE CASCADE,
  created_at TIMESTAMPTZ DEFAULT NOW(),
  is_anonymous BOOLEAN DEFAULT FALSE
);

-- User Profiles í…Œì´ë¸”
CREATE TABLE user_profiles (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  user_id UUID REFERENCES users(id) ON DELETE SET NULL,
  surgery_type TEXT NOT NULL CHECK (surgery_type IN (
    'gastric_resection',
    'colon_resection',
    'tkr',
    'spinal_fusion',
    'cholecystectomy'
  )),
  surgery_date DATE NOT NULL,
  digestive_capacity TEXT CHECK (digestive_capacity IN ('good', 'moderate', 'poor')),
  comorbidities TEXT[] DEFAULT '{}',
  current_phase TEXT,
  local_storage_key TEXT UNIQUE,
  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW()
);

-- Daily Logs í…Œì´ë¸”
CREATE TABLE daily_logs (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  profile_id UUID REFERENCES user_profiles(id) ON DELETE CASCADE,
  log_date DATE NOT NULL,
  meals_completed JSONB DEFAULT '{}',
  exercises_completed JSONB DEFAULT '{}',
  symptoms JSONB,
  notes TEXT,
  created_at TIMESTAMPTZ DEFAULT NOW(),
  UNIQUE(profile_id, log_date)
);

-- ì¸ë±ìŠ¤
CREATE INDEX idx_user_profiles_user_id ON user_profiles(user_id);
CREATE INDEX idx_user_profiles_local_key ON user_profiles(local_storage_key);
CREATE INDEX idx_daily_logs_profile ON daily_logs(profile_id);
CREATE INDEX idx_daily_logs_date ON daily_logs(log_date DESC);

-- Row Level Security í™œì„±í™”
ALTER TABLE users ENABLE ROW LEVEL SECURITY;
ALTER TABLE user_profiles ENABLE ROW LEVEL SECURITY;
ALTER TABLE daily_logs ENABLE ROW LEVEL SECURITY;

-- RLS ì •ì±…
CREATE POLICY "Users can view own data" ON users
  FOR SELECT USING (auth.uid() = id);

CREATE POLICY "Users can view own profiles" ON user_profiles
  FOR SELECT USING (auth.uid() = user_id OR user_id IS NULL);

CREATE POLICY "Users can insert own profiles" ON user_profiles
  FOR INSERT WITH CHECK (auth.uid() = user_id OR user_id IS NULL);

CREATE POLICY "Users can update own profiles" ON user_profiles
  FOR UPDATE USING (auth.uid() = user_id OR user_id IS NULL);

CREATE POLICY "Users can view own logs" ON daily_logs
  FOR SELECT USING (
    EXISTS (
      SELECT 1 FROM user_profiles
      WHERE id = daily_logs.profile_id
      AND (user_id = auth.uid() OR user_id IS NULL)
    )
  );

CREATE POLICY "Users can insert own logs" ON daily_logs
  FOR INSERT WITH CHECK (
    EXISTS (
      SELECT 1 FROM user_profiles
      WHERE id = daily_logs.profile_id
      AND (user_id = auth.uid() OR user_id IS NULL)
    )
  );

CREATE POLICY "Users can update own logs" ON daily_logs
  FOR UPDATE USING (
    EXISTS (
      SELECT 1 FROM user_profiles
      WHERE id = daily_logs.profile_id
      AND (user_id = auth.uid() OR user_id IS NULL)
    )
  );
```

**Step 2: Supabase í”„ë¡œì íŠ¸ì— ë§ˆì´ê·¸ë ˆì´ì…˜ ì ìš©**

Supabase ëŒ€ì‹œë³´ë“œì—ì„œ:
1. SQL Editor ì—´ê¸°
2. ìœ„ SQL ë³µì‚¬í•˜ì—¬ ì‹¤í–‰
3. ë˜ëŠ” Supabase CLI ì‚¬ìš©: `supabase db push`

**Step 3: ë§ˆì´ê·¸ë ˆì´ì…˜ í™•ì¸**

Supabase Table Editorì—ì„œ í…Œì´ë¸” ìƒì„± í™•ì¸:
- users
- user_profiles
- daily_logs

**Step 4: Commit**

```bash
git add supabase/
git commit -m "feat: add initial database schema migration"
```

---

### Task 5: AIìš© ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜

**Files:**
- Create: `supabase/migrations/002_vector_search.sql`

**Step 1: ë²¡í„° í™•ì¥ ë° ì§€ì‹ ë² ì´ìŠ¤ í…Œì´ë¸” ìƒì„±**

Create: `supabase/migrations/002_vector_search.sql`

```sql
-- pgvector í™•ì¥ í™œì„±í™”
CREATE EXTENSION IF NOT EXISTS vector;

-- ì§€ì‹ ë² ì´ìŠ¤ í…Œì´ë¸”
CREATE TABLE knowledge_base (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  content TEXT NOT NULL,
  embedding vector(1536),
  metadata JSONB NOT NULL DEFAULT '{}',
  created_at TIMESTAMPTZ DEFAULT NOW()
);

-- ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰ìš© IVFFlat ì¸ë±ìŠ¤
CREATE INDEX ON knowledge_base
USING ivfflat (embedding vector_cosine_ops)
WITH (lists = 100);

-- ë©”íƒ€ë°ì´í„° ê²€ìƒ‰ìš© GIN ì¸ë±ìŠ¤
CREATE INDEX idx_kb_metadata ON knowledge_base USING gin(metadata);

-- ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰ í•¨ìˆ˜
CREATE OR REPLACE FUNCTION match_documents(
  query_embedding vector(1536),
  match_threshold float DEFAULT 0.7,
  match_count int DEFAULT 5,
  filter jsonb DEFAULT '{}'::jsonb
)
RETURNS TABLE (
  id uuid,
  content text,
  metadata jsonb,
  similarity float
)
LANGUAGE plpgsql
AS $$
BEGIN
  RETURN QUERY
  SELECT
    knowledge_base.id,
    knowledge_base.content,
    knowledge_base.metadata,
    1 - (knowledge_base.embedding <=> query_embedding) AS similarity
  FROM knowledge_base
  WHERE
    1 - (knowledge_base.embedding <=> query_embedding) > match_threshold
    AND (filter = '{}'::jsonb OR knowledge_base.metadata @> filter)
  ORDER BY knowledge_base.embedding <=> query_embedding
  LIMIT match_count;
END;
$$;
```

**Step 2: Supabaseì— ë§ˆì´ê·¸ë ˆì´ì…˜ ì ìš©**

Supabase SQL Editorì—ì„œ ì‹¤í–‰

**Step 3: ë²¡í„° í™•ì¥ í™•ì¸**

```sql
SELECT * FROM pg_extension WHERE extname = 'vector';
```

Expected: vector í™•ì¥ì´ ì„¤ì¹˜ë˜ì–´ ìˆì–´ì•¼ í•¨

**Step 4: Commit**

```bash
git add supabase/migrations/002_vector_search.sql
git commit -m "feat: add pgvector extension and knowledge base schema"
```

---

### Task 6: AI ëª¨ë‹ˆí„°ë§ í…Œì´ë¸” ë§ˆì´ê·¸ë ˆì´ì…˜

**Files:**
- Create: `supabase/migrations/003_ai_tables.sql`

**Step 1: AI ê´€ë ¨ í…Œì´ë¸” ìƒì„±**

Create: `supabase/migrations/003_ai_tables.sql`

```sql
-- ëŒ€í™” íˆìŠ¤í† ë¦¬
CREATE TABLE chat_conversations (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  profile_id UUID REFERENCES user_profiles(id) ON DELETE CASCADE,
  messages JSONB NOT NULL DEFAULT '[]',
  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW()
);

CREATE INDEX idx_chat_profile ON chat_conversations(profile_id);

-- í† í° ì‚¬ìš©ëŸ‰ ì¶”ì 
CREATE TABLE token_usage (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  user_id UUID REFERENCES users(id) ON DELETE CASCADE,
  date DATE NOT NULL,
  endpoint TEXT NOT NULL,
  input_tokens INTEGER NOT NULL,
  output_tokens INTEGER NOT NULL,
  cost DECIMAL(10, 6) NOT NULL,
  created_at TIMESTAMPTZ DEFAULT NOW()
);

CREATE INDEX idx_token_usage_user_date ON token_usage(user_id, date);
CREATE INDEX idx_token_usage_date ON token_usage(date DESC);

-- AI ì„±ëŠ¥ ë©”íŠ¸ë¦­
CREATE TABLE ai_metrics (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  endpoint TEXT NOT NULL,
  model TEXT NOT NULL,
  latency_ms INTEGER NOT NULL,
  input_tokens INTEGER NOT NULL,
  output_tokens INTEGER NOT NULL,
  cost DECIMAL(10, 6) NOT NULL,
  success BOOLEAN NOT NULL,
  error_message TEXT,
  created_at TIMESTAMPTZ DEFAULT NOW()
);

CREATE INDEX idx_ai_metrics_created_at ON ai_metrics(created_at DESC);
CREATE INDEX idx_ai_metrics_success ON ai_metrics(success) WHERE NOT success;

-- RLS ì •ì±…
ALTER TABLE chat_conversations ENABLE ROW LEVEL SECURITY;
ALTER TABLE token_usage ENABLE ROW LEVEL SECURITY;
ALTER TABLE ai_metrics ENABLE ROW LEVEL SECURITY;

CREATE POLICY "Users can view own conversations" ON chat_conversations
  FOR SELECT USING (
    EXISTS (
      SELECT 1 FROM user_profiles
      WHERE id = chat_conversations.profile_id
      AND (user_id = auth.uid() OR user_id IS NULL)
    )
  );

CREATE POLICY "Users can view own token usage" ON token_usage
  FOR SELECT USING (auth.uid() = user_id);

-- ai_metricsëŠ” ê´€ë¦¬ìë§Œ ì¡°íšŒ ê°€ëŠ¥ (RLS ì •ì±… ì—†ìŒ)
```

**Step 2: Supabaseì— ë§ˆì´ê·¸ë ˆì´ì…˜ ì ìš©**

**Step 3: Commit**

```bash
git add supabase/migrations/003_ai_tables.sql
git commit -m "feat: add AI monitoring tables (conversations, token usage, metrics)"
```

---

## Phase 3: ì •ì  ë°ì´í„° êµ¬ì¶•

### Task 7: ìˆ˜ìˆ  í”„ë¡œí† ì½œ ë°ì´í„° ìƒì„±

**Files:**
- Create: `data/protocols/surgery-protocols.ts`
- Create: `lib/types/protocol.types.ts`

**Step 1: í”„ë¡œí† ì½œ íƒ€ì… ì •ì˜**

Create: `lib/types/protocol.types.ts`

```typescript
export interface RecoveryPhase {
  name: string
  daysRange: [number, number]
  description: string
  forbiddenFoods: string[]
}

export interface RehabPhase {
  name: string
  weekRange: [number, number]
  description: string
  allowedExercises: string[]
  warnings?: string[]
}

export interface SurgeryProtocol {
  phases: RecoveryPhase[]
  nutritionRequirements: {
    proteinMultiplier: number
    calorieTarget: number
    maxFatPerMeal?: number
  }
  rehabPhases?: RehabPhase[]
}

export type SurgeryType =
  | 'gastric_resection'
  | 'colon_resection'
  | 'tkr'
  | 'spinal_fusion'
  | 'cholecystectomy'
```

**Step 2: ìˆ˜ìˆ  í”„ë¡œí† ì½œ ë°ì´í„° ì‘ì„±**

Create: `data/protocols/surgery-protocols.ts`

```typescript
import type { SurgeryProtocol, SurgeryType } from '@/lib/types/protocol.types'

export const SURGERY_PROTOCOLS: Record<SurgeryType, SurgeryProtocol> = {
  gastric_resection: {
    phases: [
      {
        name: 'liquid',
        daysRange: [0, 3],
        description: 'ë¯¸ìŒ/ë§‘ì€ ìœ ë™ì‹',
        forbiddenFoods: ['ê³ ì„¬ìœ ì§ˆ', 'ê³ ì§€ë°©', 'ìê·¹ì„±']
      },
      {
        name: 'soft',
        daysRange: [4, 14],
        description: 'ì£½/ë¶€ë“œëŸ¬ìš´ ì—°ì‹',
        forbiddenFoods: ['ê³ ì„¬ìœ ì§ˆ', 'ê³ ì§€ë°©']
      },
      {
        name: 'normal',
        daysRange: [15, 60],
        description: 'ì¼ë°˜ì‹ ì ì§„ ì „í™˜',
        forbiddenFoods: ['ê³ ì§€ë°©', 'ë§¤ìš´ìŒì‹']
      }
    ],
    nutritionRequirements: {
      proteinMultiplier: 1.2,
      calorieTarget: 1800
    }
  },
  colon_resection: {
    phases: [
      {
        name: 'liquid',
        daysRange: [0, 5],
        description: 'ë§‘ì€ ìœ ë™ì‹',
        forbiddenFoods: ['ê³ ì„¬ìœ ì§ˆ', 'ìœ ì œí’ˆ', 'ìê·¹ì„±']
      },
      {
        name: 'soft',
        daysRange: [6, 21],
        description: 'ì €ì”ì‚¬ ì—°ì‹',
        forbiddenFoods: ['ê³ ì„¬ìœ ì§ˆ', 'ì”¨ì•—ë¥˜']
      },
      {
        name: 'normal',
        daysRange: [22, 90],
        description: 'ì •ìƒì‹ ë³µê·€',
        forbiddenFoods: []
      }
    ],
    nutritionRequirements: {
      proteinMultiplier: 1.0,
      calorieTarget: 2000
    }
  },
  tkr: {
    phases: [
      {
        name: 'normal',
        daysRange: [0, 90],
        description: 'ì •ìƒ ì‹ë‹¨ + ê³ ë‹¨ë°±',
        forbiddenFoods: []
      }
    ],
    nutritionRequirements: {
      proteinMultiplier: 1.5,
      calorieTarget: 2200
    },
    rehabPhases: [
      {
        name: 'protection',
        weekRange: [0, 2],
        description: 'ë³´í˜¸ê¸° - ì¹¨ìƒ ìš´ë™',
        allowedExercises: ['ankle_pump', 'quad_setting', 'heel_slide']
      },
      {
        name: 'recovery',
        weekRange: [2, 6],
        description: 'íšŒë³µê¸° - ë³´í–‰ ë° ê°€ë™ë²”ìœ„',
        allowedExercises: ['ankle_pump', 'quad_setting', 'heel_slide', 'slr', 'standing', 'walking']
      },
      {
        name: 'strengthening',
        weekRange: [6, 12],
        description: 'ê°•í™”ê¸° - ê·¼ë ¥ ê°•í™”',
        allowedExercises: ['all_previous', 'stairs', 'mini_squat', 'resistance_band']
      }
    ]
  },
  spinal_fusion: {
    phases: [
      {
        name: 'normal',
        daysRange: [0, 90],
        description: 'ì •ìƒ ì‹ë‹¨',
        forbiddenFoods: []
      }
    ],
    nutritionRequirements: {
      proteinMultiplier: 1.2,
      calorieTarget: 2000
    },
    rehabPhases: [
      {
        name: 'protection',
        weekRange: [0, 6],
        description: 'ë³´í˜¸ê¸° - ì•ˆì •',
        allowedExercises: ['walking', 'ankle_pump'],
        warnings: ['í—ˆë¦¬ ë¹„í‹€ê¸° ê¸ˆì§€', 'ë¬´ê±°ìš´ ë¬¼ê±´ ë“¤ê¸° ê¸ˆì§€']
      },
      {
        name: 'recovery',
        weekRange: [6, 12],
        description: 'íšŒë³µê¸° - ê²½ë¯¸í•œ í™œë™',
        allowedExercises: ['walking', 'core_stabilization', 'stretching']
      }
    ]
  },
  cholecystectomy: {
    phases: [
      {
        name: 'liquid',
        daysRange: [0, 1],
        description: 'ë§‘ì€ ìœ ë™ì‹',
        forbiddenFoods: ['ì§€ë°©', 'ê¸°ë¦„ì§„ìŒì‹']
      },
      {
        name: 'soft',
        daysRange: [2, 7],
        description: 'ì €ì§€ë°© ì—°ì‹',
        forbiddenFoods: ['ê³ ì§€ë°©', 'íŠ€ê¹€', 'ê¸°ë¦„ì§„ìŒì‹']
      },
      {
        name: 'normal',
        daysRange: [8, 30],
        description: 'ì €ì§€ë°© ì¼ë°˜ì‹',
        forbiddenFoods: ['ê³ ì§€ë°©']
      }
    ],
    nutritionRequirements: {
      proteinMultiplier: 1.0,
      calorieTarget: 1800,
      maxFatPerMeal: 10
    }
  }
}
```

**Step 3: Commit**

```bash
git add data/protocols/ lib/types/protocol.types.ts
git commit -m "feat: add surgery protocol data and types"
```

---

### Task 8: ì‹ë‹¨ ë° ìš´ë™ ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±

**Files:**
- Create: `data/meals/meal-database.json`
- Create: `data/exercises/exercise-database.json`
- Create: `lib/types/meal.types.ts`
- Create: `lib/types/exercise.types.ts`

**Step 1: ì‹ë‹¨ íƒ€ì… ì •ì˜**

Create: `lib/types/meal.types.ts`

```typescript
export interface Meal {
  id: string
  name: string
  textureType: 'liquid' | 'soft' | 'normal'
  nutrition: {
    calories: number
    protein: number
    carbs: number
    fat: number
    sodium: number
  }
  tags: string[]
  substitutionGroup: string
  ingredients: string[]
  prepTime: number
}
```

**Step 2: ì‹ë‹¨ ë°ì´í„° ì‘ì„±**

Create: `data/meals/meal-database.json`

```json
[
  {
    "id": "m001",
    "name": "ì†Œê³ ê¸°ë¯¸ìŒ",
    "textureType": "liquid",
    "nutrition": {
      "calories": 150,
      "protein": 8,
      "carbs": 20,
      "fat": 3,
      "sodium": 200
    },
    "tags": ["ì €ì”ì‚¬", "ê³ ë‹¨ë°±", "ë¤í•‘ì˜ˆë°©"],
    "substitutionGroup": "porridge",
    "ingredients": ["ìŒ€", "ì†Œê³ ê¸°", "ë¬¼", "ì†Œê¸ˆ"],
    "prepTime": 30
  },
  {
    "id": "m002",
    "name": "í˜¸ë°•ì£½",
    "textureType": "soft",
    "nutrition": {
      "calories": 180,
      "protein": 4,
      "carbs": 35,
      "fat": 2,
      "sodium": 150
    },
    "tags": ["ì €ì”ì‚¬", "ì €ì§€ë°©", "ì†Œí™”ì˜ë¨"],
    "substitutionGroup": "porridge",
    "ingredients": ["ìŒ€", "ë‹¨í˜¸ë°•", "ë¬¼"],
    "prepTime": 25
  },
  {
    "id": "m003",
    "name": "ë‘ë¶€ì°œ",
    "textureType": "soft",
    "nutrition": {
      "calories": 120,
      "protein": 12,
      "carbs": 5,
      "fat": 6,
      "sodium": 300
    },
    "tags": ["ê³ ë‹¨ë°±", "ì €ì§€ë°©", "ì—°ì‹"],
    "substitutionGroup": "protein_dish",
    "ingredients": ["ì—°ë‘ë¶€", "ê³„ë€", "ë‹¹ê·¼", "ê°„ì¥"],
    "prepTime": 15
  }
]
```

**Step 3: ìš´ë™ íƒ€ì… ì •ì˜**

Create: `lib/types/exercise.types.ts`

```typescript
export interface Exercise {
  id: string
  name: string
  targetSurgery: string[]
  description: string
  sets: number
  reps: number
  holdSeconds?: number
  imageUrl: string
  videoUrl?: string
  difficulty: 'easy' | 'moderate' | 'hard'
  precautions?: string[]
}
```

**Step 4: ìš´ë™ ë°ì´í„° ì‘ì„±**

Create: `data/exercises/exercise-database.json`

```json
[
  {
    "id": "ankle_pump",
    "name": "ë°œëª© íŒí”„ ìš´ë™",
    "targetSurgery": ["tkr", "spinal_fusion"],
    "description": "ëˆ„ìš´ ìì„¸ì—ì„œ ë°œëª©ì„ ìœ„ì•„ë˜ë¡œ ì›€ì§ì—¬ ì¢…ì•„ë¦¬ ê·¼ìœ¡ í™œì„±í™”",
    "sets": 3,
    "reps": 15,
    "imageUrl": "/images/exercises/ankle-pump.gif",
    "videoUrl": "https://example.com/ankle-pump",
    "difficulty": "easy"
  },
  {
    "id": "quad_setting",
    "name": "ëŒ€í‡´ì‚¬ë‘ê·¼ í˜ì£¼ê¸°",
    "targetSurgery": ["tkr"],
    "description": "ë¬´ë¦ ì•„ë˜ì— ìˆ˜ê±´ì„ ë†“ê³  ë¬´ë¦ì„ í´ë©´ì„œ ìˆ˜ê±´ì„ ëˆ„ë¥´ê¸°",
    "sets": 3,
    "reps": 10,
    "holdSeconds": 5,
    "imageUrl": "/images/exercises/quad-setting.gif",
    "difficulty": "easy"
  },
  {
    "id": "slr",
    "name": "í•˜ì§€ ì§ê±°ìƒ (SLR)",
    "targetSurgery": ["tkr"],
    "description": "ë¬´ë¦ì„ í´ê³  ë‹¤ë¦¬ë¥¼ 15cm ë“¤ì–´ì˜¬ë¦¬ê¸°",
    "sets": 3,
    "reps": 10,
    "imageUrl": "/images/exercises/slr.gif",
    "difficulty": "moderate",
    "precautions": ["2ì£¼ ì´í›„ë¶€í„° ì‹œì‘", "í†µì¦ ë°œìƒ ì‹œ ì¤‘ë‹¨"]
  }
]
```

**Step 5: Commit**

```bash
git add data/ lib/types/
git commit -m "feat: add meal and exercise databases with types"
```

---

## Phase 4: ì½”ì–´ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§

### Task 9: í”„ë¡œíŒŒì¼ë§ ì—”ì§„ êµ¬í˜„

**Files:**
- Create: `lib/profiling-engine.ts`
- Create: `lib/types/user.types.ts`

**Step 1: ì‚¬ìš©ì íƒ€ì… ì •ì˜**

Create: `lib/types/user.types.ts`

```typescript
export interface UserProfile {
  id?: string
  user_id?: string | null
  surgery_type: string
  surgery_date: Date
  digestive_capacity: 'good' | 'moderate' | 'poor'
  comorbidities: string[]
  weight?: number
  current_phase?: string
  local_storage_key?: string
  created_at?: Date
  updated_at?: Date
}
```

**Step 2: í”„ë¡œíŒŒì¼ë§ ì—”ì§„ ì‘ì„±**

Create: `lib/profiling-engine.ts`

```typescript
import { SURGERY_PROTOCOLS } from '@/data/protocols/surgery-protocols'
import type { RecoveryPhase } from './types/protocol.types'
import type { UserProfile } from './types/user.types'

export function getDaysDifference(startDate: Date, endDate: Date): number {
  const diffTime = Math.abs(endDate.getTime() - startDate.getTime())
  return Math.ceil(diffTime / (1000 * 60 * 60 * 24))
}

export function calculateRecoveryPhase(profile: UserProfile): RecoveryPhase {
  const daysSinceSurgery = getDaysDifference(profile.surgery_date, new Date())
  const protocol = SURGERY_PROTOCOLS[profile.surgery_type as keyof typeof SURGERY_PROTOCOLS]

  if (!protocol) {
    throw new Error(`Unknown surgery type: ${profile.surgery_type}`)
  }

  let phase = protocol.phases.find(
    p => daysSinceSurgery >= p.daysRange[0] && daysSinceSurgery <= p.daysRange[1]
  )

  // ì†Œí™” ëŠ¥ë ¥ì— ë”°ë¥¸ ë‹¨ê³„ ì¡°ì •
  if (profile.digestive_capacity === 'poor' && phase && phase.name !== 'liquid') {
    const currentIndex = protocol.phases.findIndex(p => p.name === phase!.name)
    if (currentIndex > 0) {
      phase = protocol.phases[currentIndex - 1]
    }
  }

  // ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ë©´ ë§ˆì§€ë§‰ ë‹¨ê³„ ë°˜í™˜
  return phase || protocol.phases[protocol.phases.length - 1]
}

export function calculateNutritionRequirements(profile: UserProfile) {
  const protocol = SURGERY_PROTOCOLS[profile.surgery_type as keyof typeof SURGERY_PROTOCOLS]
  const weight = profile.weight || 60

  return {
    dailyProtein: weight * protocol.nutritionRequirements.proteinMultiplier,
    dailyCalories: protocol.nutritionRequirements.calorieTarget,
    maxFatPerMeal: protocol.nutritionRequirements.maxFatPerMeal
  }
}
```

**Step 3: ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì‘ì„± (ì„ íƒì )**

Create: `__tests__/profiling-engine.test.ts` (ë‚˜ì¤‘ì— ì¶”ê°€)

**Step 4: Commit**

```bash
git add lib/profiling-engine.ts lib/types/user.types.ts
git commit -m "feat: add profiling engine for recovery phase calculation"
```

---

### Task 10: ë¡œì»¬ ìŠ¤í† ë¦¬ì§€ ê´€ë¦¬ì êµ¬í˜„

**Files:**
- Create: `lib/local-storage.ts`

**Step 1: ë¡œì»¬ ìŠ¤í† ë¦¬ì§€ ìœ í‹¸ë¦¬í‹° ì‘ì„±**

Create: `lib/local-storage.ts`

```typescript
import type { UserProfile } from './types/user.types'

export const LOCAL_STORAGE_KEYS = {
  PROFILE: 'recovery_profile',
  MEAL_PLAN: 'current_meal_plan',
  EXERCISE_PLAN: 'current_exercise_plan',
  DAILY_LOGS: 'daily_logs',
  LAST_SYNC: 'last_sync_timestamp'
} as const

export interface LocalProfile {
  id: string
  surgery_type: string
  surgery_date: string
  digestive_capacity: string
  comorbidities: string[]
  weight?: number
  created_at: string
  updated_at: string
}

export interface LocalDailyLog {
  date: string
  meals_completed: { [key: string]: boolean }
  exercises_completed: { [key: string]: boolean }
  symptoms?: {
    pain_level?: number
    temperature?: number
    gas_passed?: boolean
  }
  notes?: string
}

// í”„ë¡œíŒŒì¼ ì €ì¥
export function saveProfile(profile: LocalProfile): void {
  if (typeof window === 'undefined') return
  localStorage.setItem(LOCAL_STORAGE_KEYS.PROFILE, JSON.stringify(profile))
}

// í”„ë¡œíŒŒì¼ ì¡°íšŒ
export function getProfile(): LocalProfile | null {
  if (typeof window === 'undefined') return null
  const data = localStorage.getItem(LOCAL_STORAGE_KEYS.PROFILE)
  return data ? JSON.parse(data) : null
}

// ì¼ì¼ ë¡œê·¸ ì €ì¥
export function saveDailyLog(log: LocalDailyLog): void {
  if (typeof window === 'undefined') return

  const logs = getDailyLogs()
  const index = logs.findIndex(l => l.date === log.date)

  if (index >= 0) {
    logs[index] = log
  } else {
    logs.push(log)
  }

  localStorage.setItem(LOCAL_STORAGE_KEYS.DAILY_LOGS, JSON.stringify(logs))
}

// ì¼ì¼ ë¡œê·¸ ì¡°íšŒ
export function getDailyLogs(): LocalDailyLog[] {
  if (typeof window === 'undefined') return []
  const data = localStorage.getItem(LOCAL_STORAGE_KEYS.DAILY_LOGS)
  return data ? JSON.parse(data) : []
}

// ì˜¤ë˜ëœ ë¡œê·¸ ì •ë¦¬ (30ì¼ ì´ìƒ)
export function cleanupOldLogs(): void {
  if (typeof window === 'undefined') return

  const logs = getDailyLogs()
  const cutoffDate = new Date()
  cutoffDate.setDate(cutoffDate.getDate() - 30)

  const recentLogs = logs.filter(log => new Date(log.date) >= cutoffDate)

  localStorage.setItem(LOCAL_STORAGE_KEYS.DAILY_LOGS, JSON.stringify(recentLogs))
}

// í”„ë¡œíŒŒì¼ ì‚­ì œ
export function clearProfile(): void {
  if (typeof window === 'undefined') return
  localStorage.removeItem(LOCAL_STORAGE_KEYS.PROFILE)
}

// ëª¨ë“  ë°ì´í„° ì‚­ì œ
export function clearAllData(): void {
  if (typeof window === 'undefined') return
  Object.values(LOCAL_STORAGE_KEYS).forEach(key => {
    localStorage.removeItem(key)
  })
}
```

**Step 2: Commit**

```bash
git add lib/local-storage.ts
git commit -m "feat: add local storage manager for offline support"
```

---

## Phase 5: AI ì¸í”„ë¼ êµ¬ì¶•

### Task 11: OpenAI í´ë¼ì´ì–¸íŠ¸ ë° ì„ë² ë”© ìƒì„±

**Files:**
- Create: `lib/ai/embeddings.ts`

**Step 1: ì„ë² ë”© ìœ í‹¸ë¦¬í‹° ì‘ì„±**

Create: `lib/ai/embeddings.ts`

```typescript
import OpenAI from 'openai'
import { supabaseAdmin } from '@/lib/supabase-client'
import { SURGERY_PROTOCOLS } from '@/data/protocols/surgery-protocols'
import mealDatabase from '@/data/meals/meal-database.json'
import exerciseDatabase from '@/data/exercises/exercise-database.json'

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
})

export async function generateEmbedding(text: string): Promise<number[]> {
  const response = await openai.embeddings.create({
    model: 'text-embedding-3-small',
    input: text.replace(/\n/g, ' ').trim(),
  })

  return response.data[0].embedding
}

// ìˆ˜ìˆ  í”„ë¡œí† ì½œ ì¸ë±ì‹±
export async function indexSurgeryProtocols() {
  const protocols = Object.entries(SURGERY_PROTOCOLS)

  for (const [surgeryType, protocol] of protocols) {
    // íšŒë³µ ë‹¨ê³„ë³„ ì¸ë±ì‹±
    for (const phase of protocol.phases) {
      const document = `
ìˆ˜ìˆ  ì¢…ë¥˜: ${surgeryType}
íšŒë³µ ë‹¨ê³„: ${phase.name} (${phase.description})
ê¸°ê°„: ${phase.daysRange[0]}ì¼ ~ ${phase.daysRange[1]}ì¼
ê¸ˆê¸° ì‹í’ˆ: ${phase.forbiddenFoods.join(', ')}
ê¶Œì¥ ì˜ì–‘: ë‹¨ë°±ì§ˆ ${protocol.nutritionRequirements.proteinMultiplier}g/kg, ì¹¼ë¡œë¦¬ ${protocol.nutritionRequirements.calorieTarget}kcal
      `.trim()

      const embedding = await generateEmbedding(document)

      await supabaseAdmin.from('knowledge_base').insert({
        content: document,
        embedding: JSON.stringify(embedding), // pgvectorëŠ” ë°°ì—´ì„ ë¬¸ìì—´ë¡œ ë³€í™˜
        metadata: {
          category: 'protocol',
          surgery_type: surgeryType,
          phase: phase.name,
          tags: phase.forbiddenFoods
        }
      })

      console.log(`âœ… Indexed protocol: ${surgeryType} - ${phase.name}`)
    }

    // ì¬í™œ í”„ë¡œí† ì½œ ì¸ë±ì‹±
    if (protocol.rehabPhases) {
      for (const rehabPhase of protocol.rehabPhases) {
        const document = `
ìˆ˜ìˆ  ì¢…ë¥˜: ${surgeryType}
ì¬í™œ ë‹¨ê³„: ${rehabPhase.name} (${rehabPhase.description})
ì£¼ì°¨: ${rehabPhase.weekRange[0]}ì£¼ ~ ${rehabPhase.weekRange[1]}ì£¼
í—ˆìš© ìš´ë™: ${rehabPhase.allowedExercises.join(', ')}
ì£¼ì˜ì‚¬í•­: ${rehabPhase.warnings?.join('. ') || 'ì—†ìŒ'}
        `.trim()

        const embedding = await generateEmbedding(document)

        await supabaseAdmin.from('knowledge_base').insert({
          content: document,
          embedding: JSON.stringify(embedding),
          metadata: {
            category: 'rehab',
            surgery_type: surgeryType,
            phase: rehabPhase.name,
            tags: rehabPhase.allowedExercises,
            warnings: rehabPhase.warnings || []
          }
        })

        console.log(`âœ… Indexed rehab: ${surgeryType} - ${rehabPhase.name}`)
      }
    }
  }
}

// ì‹ë‹¨ ë°ì´í„°ë² ì´ìŠ¤ ì¸ë±ì‹±
export async function indexMealDatabase() {
  for (const meal of mealDatabase) {
    const document = `
ë©”ë‰´ëª…: ${meal.name}
ì‹ê° íƒ€ì…: ${meal.textureType}
ì˜ì–‘ ì •ë³´: ì¹¼ë¡œë¦¬ ${meal.nutrition.calories}kcal, ë‹¨ë°±ì§ˆ ${meal.nutrition.protein}g, íƒ„ìˆ˜í™”ë¬¼ ${meal.nutrition.carbs}g, ì§€ë°© ${meal.nutrition.fat}g, ë‚˜íŠ¸ë¥¨ ${meal.nutrition.sodium}mg
íŠ¹ì§•: ${meal.tags.join(', ')}
ì¬ë£Œ: ${meal.ingredients.join(', ')}
ì¡°ë¦¬ ì‹œê°„: ${meal.prepTime}ë¶„
ëŒ€ì²´ ê·¸ë£¹: ${meal.substitutionGroup}
    `.trim()

    const embedding = await generateEmbedding(document)

    await supabaseAdmin.from('knowledge_base').insert({
      content: document,
      embedding: JSON.stringify(embedding),
      metadata: {
        category: 'meal',
        meal_id: meal.id,
        texture_type: meal.textureType,
        tags: meal.tags,
        substitution_group: meal.substitutionGroup
      }
    })

    console.log(`âœ… Indexed meal: ${meal.name}`)
  }
}

// ìš´ë™ ë°ì´í„°ë² ì´ìŠ¤ ì¸ë±ì‹±
export async function indexExerciseDatabase() {
  for (const exercise of exerciseDatabase) {
    const document = `
ìš´ë™ëª…: ${exercise.name}
ëŒ€ìƒ ìˆ˜ìˆ : ${exercise.targetSurgery.join(', ')}
ì„¤ëª…: ${exercise.description}
ë‚œì´ë„: ${exercise.difficulty}
ì„¸íŠ¸/íšŸìˆ˜: ${exercise.sets}ì„¸íŠ¸ x ${exercise.reps}íšŒ
${exercise.holdSeconds ? `ìœ ì§€ ì‹œê°„: ${exercise.holdSeconds}ì´ˆ` : ''}
ì£¼ì˜ì‚¬í•­: ${exercise.precautions?.join('. ') || 'ì—†ìŒ'}
    `.trim()

    const embedding = await generateEmbedding(document)

    await supabaseAdmin.from('knowledge_base').insert({
      content: document,
      embedding: JSON.stringify(embedding),
      metadata: {
        category: 'exercise',
        exercise_id: exercise.id,
        target_surgery: exercise.targetSurgery,
        difficulty: exercise.difficulty,
        precautions: exercise.precautions || []
      }
    })

    console.log(`âœ… Indexed exercise: ${exercise.name}`)
  }
}
```

**Step 2: Commit**

```bash
git add lib/ai/embeddings.ts
git commit -m "feat: add OpenAI embeddings generator for knowledge base"
```

---

### Task 12: ì§€ì‹ ë² ì´ìŠ¤ ì¸ë±ì‹± ìŠ¤í¬ë¦½íŠ¸

**Files:**
- Create: `scripts/index-knowledge-base.ts`

**Step 1: ì¸ë±ì‹± ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±**

Create: `scripts/index-knowledge-base.ts`

```typescript
import {
  indexSurgeryProtocols,
  indexMealDatabase,
  indexExerciseDatabase
} from '../lib/ai/embeddings'

async function main() {
  console.log('ğŸš€ Starting knowledge base indexing...\n')

  try {
    console.log('ğŸ“‹ Indexing surgery protocols...')
    await indexSurgeryProtocols()
    console.log('âœ… Surgery protocols indexed\n')

    console.log('ğŸ½ï¸  Indexing meal database...')
    await indexMealDatabase()
    console.log('âœ… Meal database indexed\n')

    console.log('ğŸ’ª Indexing exercise database...')
    await indexExerciseDatabase()
    console.log('âœ… Exercise database indexed\n')

    console.log('ğŸ‰ Indexing complete!')
    process.exit(0)
  } catch (error) {
    console.error('âŒ Indexing failed:', error)
    process.exit(1)
  }
}

main()
```

**Step 2: package.jsonì— ìŠ¤í¬ë¦½íŠ¸ ì¶”ê°€**

Modify: `package.json`

```json
{
  "scripts": {
    "dev": "next dev",
    "build": "next build",
    "start": "next start",
    "lint": "next lint",
    "index-kb": "tsx scripts/index-knowledge-base.ts"
  }
}
```

**Step 3: tsx ì„¤ì¹˜ (TypeScript ì‹¤í–‰ìš©)**

```bash
npm install -D tsx
```

**Step 4: Commit**

```bash
git add scripts/ package.json
git commit -m "feat: add knowledge base indexing script"
```

---

## Phase 6: ê°„ë‹¨í•œ ì‹œì‘ - ëœë”© í˜ì´ì§€

### Task 13: ëœë”© í˜ì´ì§€ ë° ë ˆì´ì•„ì›ƒ

**Files:**
- Modify: `app/layout.tsx`
- Modify: `app/page.tsx`

**Step 1: ë£¨íŠ¸ ë ˆì´ì•„ì›ƒ ìˆ˜ì •**

Modify: `app/layout.tsx`

```typescript
import type { Metadata } from 'next'
import { Noto_Sans_KR } from 'next/font/google'
import './globals.css'

const notoSansKr = Noto_Sans_KR({
  subsets: ['latin'],
  weight: ['400', '700'],
  display: 'swap',
})

export const metadata: Metadata = {
  title: 'ìˆ˜ìˆ  í›„ íšŒë³µ ê´€ë¦¬ ë§¤ë‹ˆì €',
  description: 'ìˆ˜ìˆ  í›„ ì‹ë‹¨ê³¼ ì¬í™œ ìš´ë™ì„ ê´€ë¦¬í•˜ëŠ” ë””ì§€í„¸ ë™ë°˜ì',
}

export default function RootLayout({
  children,
}: {
  children: React.ReactNode
}) {
  return (
    <html lang="ko" className={notoSansKr.className}>
      <body className="min-h-screen bg-gray-50">{children}</body>
    </html>
  )
}
```

**Step 2: ëœë”© í˜ì´ì§€ ì‘ì„±**

Modify: `app/page.tsx`

```typescript
'use client'

import { useEffect, useState } from 'react'
import { useRouter } from 'next/navigation'
import { getProfile } from '@/lib/local-storage'

export default function Home() {
  const router = useRouter()
  const [loading, setLoading] = useState(true)

  useEffect(() => {
    // ë¡œì»¬ ìŠ¤í† ë¦¬ì§€ì— í”„ë¡œíŒŒì¼ì´ ìˆìœ¼ë©´ ëŒ€ì‹œë³´ë“œë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸
    const profile = getProfile()
    if (profile) {
      router.push('/dashboard')
    } else {
      setLoading(false)
    }
  }, [router])

  if (loading) {
    return (
      <div className="min-h-screen flex items-center justify-center">
        <div className="text-2xl">ë¡œë”© ì¤‘...</div>
      </div>
    )
  }

  return (
    <main className="min-h-screen flex flex-col items-center justify-center p-6">
      <div className="max-w-2xl text-center">
        <h1 className="text-5xl font-bold mb-6">
          ìˆ˜ìˆ  í›„ íšŒë³µ ê´€ë¦¬ ë§¤ë‹ˆì €
        </h1>
        <p className="text-2xl text-gray-600 mb-12">
          ìˆ˜ìˆ  ì¢…ë¥˜ì™€ íšŒë³µ ë‹¨ê³„ì— ë§ëŠ” ì‹ë‹¨ê³¼ ì¬í™œ ìš´ë™ì„
          <br />
          ìë™ìœ¼ë¡œ ìƒì„±í•´ë“œë¦½ë‹ˆë‹¤
        </p>

        <button
          onClick={() => router.push('/onboarding')}
          className="px-12 py-6 bg-blue-500 text-white text-2xl font-bold rounded-2xl
                     hover:bg-blue-600 transition-colors shadow-lg"
        >
          ì‹œì‘í•˜ê¸°
        </button>

        <div className="mt-12 grid grid-cols-3 gap-6 text-center">
          <div>
            <div className="text-4xl mb-2">ğŸ½ï¸</div>
            <p className="text-lg font-semibold">ë§ì¶¤ ì‹ë‹¨</p>
          </div>
          <div>
            <div className="text-4xl mb-2">ğŸ’ª</div>
            <p className="text-lg font-semibold">ì¬í™œ ìš´ë™</p>
          </div>
          <div>
            <div className="text-4xl mb-2">ğŸ“Š</div>
            <p className="text-lg font-semibold">íšŒë³µ ì¶”ì </p>
          </div>
        </div>
      </div>
    </main>
  )
}
```

**Step 3: ê°œë°œ ì„œë²„ì—ì„œ í™•ì¸**

```bash
npm run dev
```

http://localhost:3000 ì ‘ì†í•˜ì—¬ ëœë”© í˜ì´ì§€ í™•ì¸

**Step 4: Commit**

```bash
git add app/
git commit -m "feat: add landing page with profile redirect"
```

---

## ì‹¤í–‰ ê°€ì´ë“œ

### ì´ˆê¸° ì„¤ì • ì²´í¬ë¦¬ìŠ¤íŠ¸

**1. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •**

`.env.local` íŒŒì¼ ìƒì„±:

```bash
cp .env.local.example .env.local
```

í•„ìˆ˜ í™˜ê²½ ë³€ìˆ˜ ì…ë ¥:
- `NEXT_PUBLIC_SUPABASE_URL` - Supabase í”„ë¡œì íŠ¸ URL
- `NEXT_PUBLIC_SUPABASE_ANON_KEY` - Supabase anon public key
- `SUPABASE_SERVICE_ROLE_KEY` - Supabase service role key
- `OPENAI_API_KEY` - OpenAI API í‚¤

**2. ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜**

Supabase SQL Editorì—ì„œ ìˆœì„œëŒ€ë¡œ ì‹¤í–‰:
1. `supabase/migrations/001_initial_schema.sql`
2. `supabase/migrations/002_vector_search.sql`
3. `supabase/migrations/003_ai_tables.sql`

**3. ì§€ì‹ ë² ì´ìŠ¤ ì¸ë±ì‹±**

```bash
npm run index-kb
```

Expected output:
```
ğŸš€ Starting knowledge base indexing...
ğŸ“‹ Indexing surgery protocols...
âœ… Indexed protocol: gastric_resection - liquid
âœ… Indexed protocol: gastric_resection - soft
...
ğŸ‰ Indexing complete!
```

**4. ê°œë°œ ì„œë²„ ì‹¤í–‰**

```bash
npm run dev
```

### ê°œë°œ ì›Œí¬í”Œë¡œìš°

**ë§¤ ì‘ì—…ë§ˆë‹¤:**
1. ê¸°ëŠ¥ êµ¬í˜„
2. ë¡œì»¬ í…ŒìŠ¤íŠ¸
3. ì»¤ë°‹ (ëª…í™•í•œ ì»¤ë°‹ ë©”ì‹œì§€)
4. ë‹¤ìŒ Taskë¡œ ì§„í–‰

**ê¶Œì¥ ì»¤ë°‹ ë©”ì‹œì§€ í˜•ì‹:**
- `feat: add [ê¸°ëŠ¥]` - ìƒˆ ê¸°ëŠ¥
- `fix: resolve [ë²„ê·¸]` - ë²„ê·¸ ìˆ˜ì •
- `refactor: improve [ë¶€ë¶„]` - ë¦¬íŒ©í† ë§
- `chore: update [í•­ëª©]` - ì„¤ì •/ë„êµ¬ ë³€ê²½

### ë‹¤ìŒ ë‹¨ê³„ (Phase 6-10)

ì´ ê³„íšì„œëŠ” **Phase 1-5 (Foundation + AI Infrastructure)**ê¹Œì§€ í¬í•¨í•©ë‹ˆë‹¤.

**Phase 6-10 (ë³„ë„ êµ¬í˜„ ê³„íš í•„ìš”):**
- Phase 6: ì˜¨ë³´ë”© í”Œë¡œìš° UI
- Phase 7: ëŒ€ì‹œë³´ë“œ ë° ì‹ë‹¨/ìš´ë™ í˜ì´ì§€
- Phase 8: AI ì±—ë´‡ êµ¬í˜„
- Phase 9: ì¦ìƒ ë¶„ì„ ë° ì£¼ê°„ ë¦¬í¬íŠ¸
- Phase 10: PDF ìƒì„± ë° ìµœì í™”

ê° PhaseëŠ” ë…ë¦½ì ì¸ êµ¬í˜„ ê³„íšìœ¼ë¡œ ì‘ì„±í•˜ì—¬ ìˆœì°¨ì ìœ¼ë¡œ ì§„í–‰í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.

---

## ì‹¤í–‰ ì˜µì…˜

**Plan complete and saved to `docs/plans/2026-01-24-implementation-plan.md`.**

**Two execution options:**

**1. Subagent-Driven (this session)** - I dispatch fresh subagent per task, review between tasks, fast iteration
- **REQUIRED SUB-SKILL:** Use superpowers:subagent-driven-development
- Stay in this session
- Fresh subagent per task + code review

**2. Parallel Session (separate)** - Open new session with executing-plans, batch execution with checkpoints
- Guide them to open new session in worktree
- **REQUIRED SUB-SKILL:** New session uses superpowers:executing-plans

**Which approach?**
