# LLM í†µí•© ë””ìì¸ - ìˆ˜ìˆ  í›„ íšŒë³µ ê´€ë¦¬ ë§¤ë‹ˆì €

**ì‘ì„±ì¼**: 2026-01-24
**ë²„ì „**: 1.0
**ìƒíƒœ**: Approved
**ê¸°ë°˜ ë¬¸ì„œ**: [2026-01-24-recovery-manager-design.md](./2026-01-24-recovery-manager-design.md)

## ê°œìš”

ê¸°ì¡´ ë£° ê¸°ë°˜ íšŒë³µ ê´€ë¦¬ ì‹œìŠ¤í…œì— OpenAI GPT-4oë¥¼ í†µí•©í•˜ì—¬ ë‹¤ìŒ ê¸°ëŠ¥ì„ AIë¡œ ê°•í™”í•©ë‹ˆë‹¤:
1. **ëŒ€í™”í˜• ì§ˆë¬¸ì‘ë‹µ ì±—ë´‡** - 24/7 ê°€ìƒ ê°„í˜¸ì‚¬
2. **ìŠ¤ë§ˆíŠ¸ ì‹ë‹¨ ìƒì„±** - ê°œì¸ ì„ í˜¸ë„ ë°˜ì˜ ë§ì¶¤ ì‹ë‹¨
3. **ì¦ìƒ ë¶„ì„ ë° ë¦¬ìŠ¤í¬ í‰ê°€** - ì§€ëŠ¥í˜• ê±´ê°• ëª¨ë‹ˆí„°ë§
4. **ì£¼ê°„ ë¦¬í¬íŠ¸ ìë™ ìƒì„±** - ìì—°ì–´ í”¼ë“œë°±

## í•µì‹¬ ê²°ì •ì‚¬í•­

- **LLM ì„œë¹„ìŠ¤**: OpenAI GPT-4o (í•œêµ­ì–´ ìš°ìˆ˜, Function Calling ì§€ì›)
- **ì„ë² ë”© ëª¨ë¸**: text-embedding-3-small (1536 ì°¨ì›)
- **ê²€ìƒ‰ ë°©ì‹**: RAG (Retrieval-Augmented Generation)
- **ë²¡í„° DB**: Supabase pgvector (ê¸°ì¡´ ì¸í”„ë¼ í™œìš©)
- **ë¹„ìš© ëª©í‘œ**: ì‚¬ìš©ìë‹¹ ì›” $0.40 ì´í•˜ (ìµœì í™” í›„)

---

## 1. LLM í†µí•© ì•„í‚¤í…ì²˜

### ì „ì²´ í”Œë¡œìš°

```
ì‚¬ìš©ì ì§ˆë¬¸
  â†“
[1] ì…ë ¥ ê²€ì¦ (í”„ë¡¬í”„íŠ¸ ì¸ì ì…˜ ë°©ì§€)
  â†“
[2] OpenAI Embeddings API
  â†“
[3] Supabase pgvector ìœ ì‚¬ë„ ê²€ìƒ‰
  â†“
[4] ê´€ë ¨ ë¬¸ì„œ + ì‚¬ìš©ì í”„ë¡œíŒŒì¼ ê²°í•©
  â†“
[5] GPT-4o í”„ë¡¬í”„íŠ¸ ìƒì„±
  â†“
[6] OpenAI Chat Completion API
  â†“
[7] ì‘ë‹µ ê²€ì¦ (ì˜ë£Œ ë©´ì±… ì¡°í•­ í™•ì¸)
  â†“
[8] ì‚¬ìš©ìì—ê²Œ ë°˜í™˜
  â†“
[9] ëŒ€í™” íˆìŠ¤í† ë¦¬ ì €ì¥ + í† í° ì‚¬ìš©ëŸ‰ ì¶”ì 
```

### ê¸°ìˆ  ìŠ¤íƒ ì¶”ê°€

**AI/ML**
- OpenAI GPT-4o - í…ìŠ¤íŠ¸ ìƒì„±
- OpenAI text-embedding-3-small - ë²¡í„° ì„ë² ë”©
- Supabase pgvector - ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤

**ëª¨ë‹ˆí„°ë§**
- Upstash Redis - Rate limiting (ì„ íƒì )
- Supabase Analytics - í† í° ì‚¬ìš©ëŸ‰ ì¶”ì 

---

## 2. ë°ì´í„°ë² ì´ìŠ¤ í™•ì¥

### ë²¡í„° í™•ì¥ ë° ì§€ì‹ ë² ì´ìŠ¤

```sql
-- supabase/migrations/002_vector_search.sql

-- ë²¡í„° í™•ì¥ í™œì„±í™”
CREATE EXTENSION IF NOT EXISTS vector;

-- ì§€ì‹ ë² ì´ìŠ¤ í…Œì´ë¸”
CREATE TABLE knowledge_base (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  content TEXT NOT NULL,              -- ì›ë³¸ í…ìŠ¤íŠ¸
  embedding vector(1536),              -- ë²¡í„° ì„ë² ë”©
  metadata JSONB NOT NULL,             -- ì¹´í…Œê³ ë¦¬, íƒœê·¸ ë“±
  created_at TIMESTAMPTZ DEFAULT NOW()
);

-- ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰ìš© ì¸ë±ìŠ¤ (IVFFlat ì•Œê³ ë¦¬ì¦˜)
CREATE INDEX ON knowledge_base
USING ivfflat (embedding vector_cosine_ops)
WITH (lists = 100);

-- ë©”íƒ€ë°ì´í„° ê²€ìƒ‰ìš© ì¸ë±ìŠ¤
CREATE INDEX idx_kb_metadata ON knowledge_base USING gin(metadata);

-- ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰ í•¨ìˆ˜
CREATE OR REPLACE FUNCTION match_documents(
  query_embedding vector(1536),
  match_threshold float DEFAULT 0.7,
  match_count int DEFAULT 5,
  filter jsonb DEFAULT '{}'::jsonb
)
RETURNS TABLE (
  id uuid,
  content text,
  metadata jsonb,
  similarity float
)
LANGUAGE plpgsql
AS $$
BEGIN
  RETURN QUERY
  SELECT
    knowledge_base.id,
    knowledge_base.content,
    knowledge_base.metadata,
    1 - (knowledge_base.embedding <=> query_embedding) AS similarity
  FROM knowledge_base
  WHERE
    1 - (knowledge_base.embedding <=> query_embedding) > match_threshold
    AND (filter = '{}'::jsonb OR knowledge_base.metadata @> filter)
  ORDER BY knowledge_base.embedding <=> query_embedding
  LIMIT match_count;
END;
$$;
```

### ëŒ€í™” ë° ëª¨ë‹ˆí„°ë§ í…Œì´ë¸”

```sql
-- supabase/migrations/003_ai_tables.sql

-- ëŒ€í™” íˆìŠ¤í† ë¦¬
CREATE TABLE chat_conversations (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  profile_id UUID REFERENCES user_profiles(id) ON DELETE CASCADE,
  messages JSONB NOT NULL,  -- [{role, content, timestamp}]
  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW()
);

CREATE INDEX idx_chat_profile ON chat_conversations(profile_id);

-- í† í° ì‚¬ìš©ëŸ‰ ì¶”ì 
CREATE TABLE token_usage (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  user_id UUID REFERENCES users(id) ON DELETE CASCADE,
  date DATE NOT NULL,
  endpoint TEXT NOT NULL,          -- 'chat', 'meal_plan', 'symptom_analysis'
  input_tokens INTEGER NOT NULL,
  output_tokens INTEGER NOT NULL,
  cost DECIMAL(10, 6) NOT NULL,
  created_at TIMESTAMPTZ DEFAULT NOW()
);

CREATE INDEX idx_token_usage_user_date ON token_usage(user_id, date);

-- AI ì„±ëŠ¥ ë©”íŠ¸ë¦­
CREATE TABLE ai_metrics (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  endpoint TEXT NOT NULL,
  model TEXT NOT NULL,
  latency_ms INTEGER NOT NULL,
  input_tokens INTEGER NOT NULL,
  output_tokens INTEGER NOT NULL,
  cost DECIMAL(10, 6) NOT NULL,
  success BOOLEAN NOT NULL,
  error_message TEXT,
  created_at TIMESTAMPTZ DEFAULT NOW()
);

CREATE INDEX idx_ai_metrics_created_at ON ai_metrics(created_at DESC);
CREATE INDEX idx_ai_metrics_success ON ai_metrics(success) WHERE NOT success;
```

---

## 3. ë²¡í„° ì„ë² ë”© ìƒì„±

### ì„ë² ë”© ìœ í‹¸ë¦¬í‹°

```typescript
// /lib/ai/embeddings.ts
import OpenAI from 'openai'
import { supabase } from '@/lib/supabase-client'
import { SURGERY_PROTOCOLS } from '@/data/protocols/surgery-protocols'
import { MEAL_DATABASE } from '@/data/meals/meal-database.json'
import { EXERCISE_DATABASE } from '@/data/exercises/exercise-database.json'

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
})

export async function generateEmbedding(text: string): Promise<number[]> {
  const response = await openai.embeddings.create({
    model: 'text-embedding-3-small',
    input: text.replace(/\n/g, ' ').trim(),
  })

  return response.data[0].embedding
}

// ìˆ˜ìˆ  í”„ë¡œí† ì½œ ì¸ë±ì‹±
export async function indexSurgeryProtocols() {
  const protocols = Object.entries(SURGERY_PROTOCOLS)

  for (const [surgeryType, protocol] of protocols) {
    // ê° íšŒë³µ ë‹¨ê³„ë³„ ì¸ë±ì‹±
    for (const phase of protocol.phases) {
      const document = `
ìˆ˜ìˆ  ì¢…ë¥˜: ${surgeryType}
íšŒë³µ ë‹¨ê³„: ${phase.name} (${phase.description})
ê¸°ê°„: ${phase.daysRange[0]}ì¼ ~ ${phase.daysRange[1]}ì¼
ê¸ˆê¸° ì‹í’ˆ: ${phase.forbiddenFoods.join(', ')}
ê¶Œì¥ ì˜ì–‘: ë‹¨ë°±ì§ˆ ${protocol.nutritionRequirements.proteinMultiplier}g/kg, ì¹¼ë¡œë¦¬ ${protocol.nutritionRequirements.calorieTarget}kcal
      `.trim()

      const embedding = await generateEmbedding(document)

      await supabase.from('knowledge_base').insert({
        content: document,
        embedding,
        metadata: {
          category: 'protocol',
          surgery_type: surgeryType,
          phase: phase.name,
          tags: phase.forbiddenFoods
        }
      })
    }

    // ì¬í™œ í”„ë¡œí† ì½œ ì¸ë±ì‹± (ì •í˜•ì™¸ê³¼ ìˆ˜ìˆ )
    if (protocol.rehabPhases) {
      for (const rehabPhase of protocol.rehabPhases) {
        const document = `
ìˆ˜ìˆ  ì¢…ë¥˜: ${surgeryType}
ì¬í™œ ë‹¨ê³„: ${rehabPhase.name} (${rehabPhase.description})
ì£¼ì°¨: ${rehabPhase.weekRange[0]}ì£¼ ~ ${rehabPhase.weekRange[1]}ì£¼
í—ˆìš© ìš´ë™: ${rehabPhase.allowedExercises.join(', ')}
ì£¼ì˜ì‚¬í•­: ${rehabPhase.warnings?.join('. ') || 'ì—†ìŒ'}
        `.trim()

        const embedding = await generateEmbedding(document)

        await supabase.from('knowledge_base').insert({
          content: document,
          embedding,
          metadata: {
            category: 'rehab',
            surgery_type: surgeryType,
            phase: rehabPhase.name,
            tags: rehabPhase.allowedExercises,
            warnings: rehabPhase.warnings || []
          }
        })
      }
    }
  }
}

// ì‹ë‹¨ ë°ì´í„°ë² ì´ìŠ¤ ì¸ë±ì‹±
export async function indexMealDatabase() {
  for (const meal of MEAL_DATABASE) {
    const document = `
ë©”ë‰´ëª…: ${meal.name}
ì‹ê° íƒ€ì…: ${meal.textureType}
ì˜ì–‘ ì •ë³´: ì¹¼ë¡œë¦¬ ${meal.nutrition.calories}kcal, ë‹¨ë°±ì§ˆ ${meal.nutrition.protein}g, íƒ„ìˆ˜í™”ë¬¼ ${meal.nutrition.carbs}g, ì§€ë°© ${meal.nutrition.fat}g, ë‚˜íŠ¸ë¥¨ ${meal.nutrition.sodium}mg
íŠ¹ì§•: ${meal.tags.join(', ')}
ì¬ë£Œ: ${meal.ingredients.join(', ')}
ì¡°ë¦¬ ì‹œê°„: ${meal.prepTime}ë¶„
ëŒ€ì²´ ê·¸ë£¹: ${meal.substitutionGroup}
    `.trim()

    const embedding = await generateEmbedding(document)

    await supabase.from('knowledge_base').insert({
      content: document,
      embedding,
      metadata: {
        category: 'meal',
        meal_id: meal.id,
        texture_type: meal.textureType,
        tags: meal.tags,
        substitution_group: meal.substitutionGroup
      }
    })
  }
}

// ìš´ë™ ë°ì´í„°ë² ì´ìŠ¤ ì¸ë±ì‹±
export async function indexExerciseDatabase() {
  for (const exercise of EXERCISE_DATABASE) {
    const document = `
ìš´ë™ëª…: ${exercise.name}
ëŒ€ìƒ ìˆ˜ìˆ : ${exercise.targetSurgery.join(', ')}
ì„¤ëª…: ${exercise.description}
ë‚œì´ë„: ${exercise.difficulty}
ì„¸íŠ¸/íšŸìˆ˜: ${exercise.sets}ì„¸íŠ¸ x ${exercise.reps}íšŒ
${exercise.holdSeconds ? `ìœ ì§€ ì‹œê°„: ${exercise.holdSeconds}ì´ˆ` : ''}
ì£¼ì˜ì‚¬í•­: ${exercise.precautions?.join('. ') || 'ì—†ìŒ'}
    `.trim()

    const embedding = await generateEmbedding(document)

    await supabase.from('knowledge_base').insert({
      content: document,
      embedding,
      metadata: {
        category: 'exercise',
        exercise_id: exercise.id,
        target_surgery: exercise.targetSurgery,
        difficulty: exercise.difficulty,
        precautions: exercise.precautions || []
      }
    })
  }
}
```

### ì´ˆê¸° ì¸ë±ì‹± ìŠ¤í¬ë¦½íŠ¸

```typescript
// /scripts/index-knowledge-base.ts
import {
  indexSurgeryProtocols,
  indexMealDatabase,
  indexExerciseDatabase
} from '@/lib/ai/embeddings'

async function main() {
  console.log('ğŸš€ Starting knowledge base indexing...\n')

  try {
    console.log('ğŸ“‹ Indexing surgery protocols...')
    await indexSurgeryProtocols()
    console.log('âœ… Surgery protocols indexed\n')

    console.log('ğŸ½ï¸  Indexing meal database...')
    await indexMealDatabase()
    console.log('âœ… Meal database indexed\n')

    console.log('ğŸ’ª Indexing exercise database...')
    await indexExerciseDatabase()
    console.log('âœ… Exercise database indexed\n')

    console.log('ğŸ‰ Indexing complete!')
  } catch (error) {
    console.error('âŒ Indexing failed:', error)
    process.exit(1)
  }
}

main()
```

```json
// package.json ìŠ¤í¬ë¦½íŠ¸ ì¶”ê°€
{
  "scripts": {
    "dev": "next dev",
    "build": "next build",
    "start": "next start",
    "index-kb": "tsx scripts/index-knowledge-base.ts"
  }
}
```

---

## 4. RAG ê²€ìƒ‰ ë¡œì§

```typescript
// /lib/ai/rag-search.ts
import { generateEmbedding } from './embeddings'
import { supabase } from '@/lib/supabase-client'

export interface KnowledgeDocument {
  id: string
  content: string
  metadata: {
    category: string
    [key: string]: any
  }
  similarity: number
}

export async function searchKnowledgeBase(
  query: string,
  profile: UserProfile,
  options: {
    limit?: number
    threshold?: number
    category?: string
  } = {}
): Promise<KnowledgeDocument[]> {
  const {
    limit = 5,
    threshold = 0.7,
    category
  } = options

  // 1. ì§ˆë¬¸ì„ ë²¡í„°ë¡œ ë³€í™˜
  const queryEmbedding = await generateEmbedding(query)

  // 2. ì‚¬ìš©ì ìˆ˜ìˆ  íƒ€ì…ì— ë§ëŠ” í•„í„°
  const filter: any = {
    surgery_type: profile.surgery_type
  }

  if (category) {
    filter.category = category
  }

  // 3. ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰
  const { data, error } = await supabase.rpc('match_documents', {
    query_embedding: queryEmbedding,
    match_threshold: threshold,
    match_count: limit,
    filter
  })

  if (error) {
    console.error('RAG search error:', error)
    throw error
  }

  return data || []
}

// í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰: ë²¡í„° + í‚¤ì›Œë“œ
export async function hybridSearch(
  query: string,
  profile: UserProfile,
  keywords: string[]
): Promise<KnowledgeDocument[]> {
  const vectorResults = await searchKnowledgeBase(query, profile, { limit: 10 })

  // í‚¤ì›Œë“œ ë§¤ì¹­ìœ¼ë¡œ ì¬ì •ë ¬
  const scored = vectorResults.map(doc => {
    let keywordScore = 0
    const content = doc.content.toLowerCase()

    keywords.forEach(keyword => {
      if (content.includes(keyword.toLowerCase())) {
        keywordScore += 0.1
      }
    })

    return {
      ...doc,
      finalScore: doc.similarity + keywordScore
    }
  })

  return scored
    .sort((a, b) => b.finalScore - a.finalScore)
    .slice(0, 5)
}
```

---

## 5. AI ì§ˆë¬¸ì‘ë‹µ ì±—ë´‡

```typescript
// /lib/ai/chat-assistant.ts
import OpenAI from 'openai'
import { searchKnowledgeBase } from './rag-search'
import { sanitizeUserInput, validateAIResponse } from './safety-guardrails'
import { calculateRecoveryPhase, getDaysDifference } from '@/lib/profiling-engine'

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY })

export interface ChatMessage {
  role: 'user' | 'assistant'
  content: string
  timestamp: Date
}

export async function chatWithAssistant(
  userMessage: string,
  profile: UserProfile,
  conversationHistory: ChatMessage[] = []
): Promise<{ response: string, usage: any }> {
  // 1. ì…ë ¥ ê²€ì¦
  const sanitizedMessage = sanitizeUserInput(userMessage)

  // 2. RAGë¡œ ê´€ë ¨ ì§€ì‹ ê²€ìƒ‰
  const relevantDocs = await searchKnowledgeBase(
    sanitizedMessage,
    profile,
    { limit: 3, threshold: 0.7 }
  )

  // 3. ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
  const contextDocs = relevantDocs
    .map(doc => `[${doc.metadata.category}]\n${doc.content}`)
    .join('\n\n---\n\n')

  const daysSinceSurgery = getDaysDifference(profile.surgery_date, new Date())
  const currentPhase = calculateRecoveryPhase(profile)

  // 4. System Prompt
  const systemPrompt = `
ë‹¹ì‹ ì€ ìˆ˜ìˆ  í›„ íšŒë³µì„ ë•ëŠ” ì¹œì ˆí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

## í™˜ì ì •ë³´
- ìˆ˜ìˆ  ì¢…ë¥˜: ${profile.surgery_type}
- ìˆ˜ìˆ ì¼: ${formatDate(profile.surgery_date)} (D+${daysSinceSurgery}ì¼)
- í˜„ì¬ íšŒë³µ ë‹¨ê³„: ${currentPhase.description}
- ì†Œí™” ëŠ¥ë ¥: ${profile.digestive_capacity}
- ë™ë°˜ ì§ˆí™˜: ${profile.comorbidities.join(', ') || 'ì—†ìŒ'}

## ê´€ë ¨ ì§€ì‹
${contextDocs || '(ê²€ìƒ‰ëœ ê´€ë ¨ ì •ë³´ ì—†ìŒ)'}

## ì‘ë‹µ ì§€ì¹¨
1. **ì‰¬ìš´ ì–¸ì–´**: ê³ ë ¹ ì‚¬ìš©ìë¥¼ ê³ ë ¤í•˜ì—¬ ì˜í•™ ìš©ì–´ ìµœì†Œí™”
2. **ì§§ì€ ë¬¸ì¥**: í•œ ë¬¸ì¥ 30ì ì´ë‚´ ê¶Œì¥, ì¤„ë°”ê¿ˆìœ¼ë¡œ ê°€ë…ì„± í–¥ìƒ
3. **ê¸´ê¸‰ ìƒí™© ê°ì§€**: ë‹¤ìŒ ì¦ìƒ ì‹œ ì¦‰ì‹œ ë³‘ì› ë°©ë¬¸ ê¶Œê³ 
   - ì²´ì˜¨ 38.5Â°C ì´ìƒ
   - í†µì¦ ìˆ˜ì¹˜ 8 ì´ìƒ
   - ì‹¬í•œ ë¶€ì¢…/ë°œì 
   - 48ì‹œê°„ ì´ìƒ ê°€ìŠ¤ ë°°ì¶œ ì—†ìŒ (ì†Œí™”ê¸° ìˆ˜ìˆ )
4. **ë¶ˆí™•ì‹¤ì„± ì¸ì •**: í™•ì‹¤í•˜ì§€ ì•Šìœ¼ë©´ "ë‹´ë‹¹ ì˜ë£Œì§„ê³¼ ìƒì˜í•˜ì„¸ìš”"
5. **ì¹œê·¼í•œ í†¤**: ì´ëª¨ì§€ ì ì ˆíˆ ì‚¬ìš© (ğŸ˜Š ğŸ½ï¸ ğŸ’ª ë“±)

## ì˜ë£Œ ë©´ì±…
**ì¤‘ìš”**: ë³¸ ì„œë¹„ìŠ¤ëŠ” ì˜ë£Œ ì¡°ì–¸ì„ ëŒ€ì²´í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
ëª¨ë“  ë‹µë³€ ëì— ë°˜ë“œì‹œ "ê¶ê¸ˆí•œ ì ì€ ë‹´ë‹¹ ì˜ì‚¬ ì„ ìƒë‹˜ê³¼ ìƒë‹´í•˜ì„¸ìš” ğŸ˜Š"ë¥¼ ì¶”ê°€í•˜ì„¸ìš”.
  `.trim()

  // 5. ëŒ€í™” ë©”ì‹œì§€ êµ¬ì„±
  const messages: OpenAI.Chat.ChatCompletionMessageParam[] = [
    { role: 'system', content: systemPrompt },
    ...conversationHistory.slice(-6).map(msg => ({
      role: msg.role as 'user' | 'assistant',
      content: msg.content
    })),
    { role: 'user', content: sanitizedMessage }
  ]

  // 6. GPT-4o í˜¸ì¶œ
  const response = await openai.chat.completions.create({
    model: 'gpt-4o',
    messages,
    temperature: 0.7,
    max_tokens: 500,
  })

  const aiResponse = response.choices[0].message.content || 'ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'

  // 7. ì‘ë‹µ ê²€ì¦
  if (!validateAIResponse(aiResponse)) {
    throw new Error('AI ì‘ë‹µì´ ì•ˆì „ ê¸°ì¤€ì„ ì¶©ì¡±í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.')
  }

  return {
    response: aiResponse,
    usage: response.usage
  }
}

function formatDate(date: Date): string {
  return new Intl.DateTimeFormat('ko-KR').format(date)
}
```

---

## 6. AI ìŠ¤ë§ˆíŠ¸ ì‹ë‹¨ ìƒì„±

```typescript
// /lib/ai/meal-generator.ts
import OpenAI from 'openai'
import { searchKnowledgeBase } from './rag-search'
import { calculateRecoveryPhase } from '@/lib/profiling-engine'
import { SURGERY_PROTOCOLS } from '@/data/protocols/surgery-protocols'

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY })

export interface MealPreferences {
  dislikedFoods?: string[]
  availableIngredients?: string[]
  preferredCuisine?: string
}

export async function generateAIMealPlan(
  profile: UserProfile,
  preferences?: MealPreferences
): Promise<{ mealPlan: WeeklyMealPlan, usage: any }> {
  const currentPhase = calculateRecoveryPhase(profile)
  const protocol = SURGERY_PROTOCOLS[profile.surgery_type]

  // 1. ì‚¬ìš© ê°€ëŠ¥í•œ ì‹ë‹¨ ê²€ìƒ‰
  const mealQuery = `${currentPhase.name} ì‹ê°ì˜ ${profile.surgery_type} ìˆ˜ìˆ  í›„ ì‹ë‹¨`
  const relevantMeals = await searchKnowledgeBase(
    mealQuery,
    profile,
    { limit: 20, category: 'meal' }
  )

  // 2. í”„ë¡¬í”„íŠ¸ êµ¬ì„±
  const prompt = `
ë‹¤ìŒ ì¡°ê±´ì— ë§ëŠ” 7ì¼ê°„ì˜ ì‹ë‹¨ì„ JSON í˜•ì‹ìœ¼ë¡œ ìƒì„±í•˜ì„¸ìš”.

## í™˜ì ì •ë³´
- ìˆ˜ìˆ : ${profile.surgery_type}
- í˜„ì¬ íšŒë³µ ë‹¨ê³„: ${currentPhase.description}
- ê¸ˆê¸° ì‹í’ˆ: ${currentPhase.forbiddenFoods.join(', ')}
- ì¼ì¼ ë‹¨ë°±ì§ˆ ëª©í‘œ: ${(profile.weight || 60) * protocol.nutritionRequirements.proteinMultiplier}g
- ì¼ì¼ ì¹¼ë¡œë¦¬ ëª©í‘œ: ${protocol.calorieTarget}kcal

## ì‚¬ìš©ì ì„ í˜¸
- ì‹«ì–´í•˜ëŠ” ìŒì‹: ${preferences?.dislikedFoods?.join(', ') || 'ì—†ìŒ'}
- ëƒ‰ì¥ê³  ì¬ë£Œ: ${preferences?.availableIngredients?.join(', ') || 'ì—†ìŒ'}
- ì„ í˜¸ ìŠ¤íƒ€ì¼: ${preferences?.preferredCuisine || 'í•œì‹'}

## ì‚¬ìš© ê°€ëŠ¥í•œ ë©”ë‰´ ì˜µì…˜
${relevantMeals.map(m => m.content).slice(0, 15).join('\n\n')}

## ì¶œë ¥ í˜•ì‹ (JSON)
\`\`\`json
{
  "ì›”": {
    "breakfast": {
      "name": "ì†Œê³ ê¸°ë¯¸ìŒ",
      "reason": "ì†Œí™”ê°€ ì˜ ë˜ê³  ë‹¨ë°±ì§ˆ ë³´ì¶©ì— ì¢‹ìŠµë‹ˆë‹¤"
    },
    "lunch": { "name": "...", "reason": "..." },
    "dinner": { "name": "...", "reason": "..." }
  },
  "í™”": { ... },
  ... (ìˆ˜~ì¼)
}
\`\`\`

## ì œì•½ì‚¬í•­
1. **ê¸ˆê¸° ì‹í’ˆ ì ˆëŒ€ í¬í•¨ ê¸ˆì§€**
2. ì˜ì–‘ ê· í˜• ê³ ë ¤ (ë‹¨ë°±ì§ˆ/íƒ„ìˆ˜í™”ë¬¼/ì§€ë°© ë¹„ìœ¨)
3. ë‹¤ì–‘ì„± í™•ë³´ (ê°™ì€ ë©”ë‰´ í•˜ë£¨ì— 2ë²ˆ ì´ìƒ ë°˜ë³µ ê¸ˆì§€)
4. ëƒ‰ì¥ê³  ì¬ë£Œê°€ ìˆìœ¼ë©´ ìš°ì„  í™œìš©
5. ì‹«ì–´í•˜ëŠ” ìŒì‹ ì œì™¸
  `.trim()

  // 3. GPT-4o í˜¸ì¶œ (JSON ëª¨ë“œ)
  const response = await openai.chat.completions.create({
    model: 'gpt-4o',
    messages: [{ role: 'user', content: prompt }],
    response_format: { type: 'json_object' },
    temperature: 0.8,  // ì°½ì˜ì„± í–¥ìƒ
    max_tokens: 2000,
  })

  const aiMealPlan = JSON.parse(response.choices[0].message.content || '{}')

  // 4. ë°ì´í„° ëª¨ë¸ ë³€í™˜
  const weeklyMealPlan: WeeklyMealPlan = {}
  const days = ['ì›”', 'í™”', 'ìˆ˜', 'ëª©', 'ê¸ˆ', 'í† ', 'ì¼']

  days.forEach(day => {
    if (aiMealPlan[day]) {
      weeklyMealPlan[day] = {
        breakfast: {
          name: aiMealPlan[day].breakfast.name,
          reason: aiMealPlan[day].breakfast.reason,
          // ì‹¤ì œ meal ê°ì²´ëŠ” DBì—ì„œ ì¡°íšŒ
        },
        lunch: {
          name: aiMealPlan[day].lunch.name,
          reason: aiMealPlan[day].lunch.reason,
        },
        dinner: {
          name: aiMealPlan[day].dinner.name,
          reason: aiMealPlan[day].dinner.reason,
        }
      }
    }
  })

  return {
    mealPlan: weeklyMealPlan,
    usage: response.usage
  }
}
```

---

## 7. ì¦ìƒ ë¶„ì„ ë° ë¦¬ìŠ¤í¬ í‰ê°€

```typescript
// /lib/ai/symptom-analyzer.ts
import OpenAI from 'openai'
import { getDaysDifference } from '@/lib/profiling-engine'

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY })

export interface SymptomInput {
  pain_level: number          // 0-10
  temperature?: number        // ì„­ì”¨
  gas_passed: boolean
  other_symptoms?: string
}

export interface SymptomAnalysis {
  riskLevel: 'low' | 'medium' | 'high'
  recommendation: string
  shouldContactDoctor: boolean
  explanation: string
}

export async function analyzeSymptoms(
  symptoms: SymptomInput,
  profile: UserProfile,
  recentLogs: LocalDailyLog[]
): Promise<{ analysis: SymptomAnalysis, usage: any }> {
  const daysSinceSurgery = getDaysDifference(profile.surgery_date, new Date())

  // ì¦ìƒ íŠ¸ë Œë“œ ë¶„ì„
  const symptomTrend = recentLogs
    .filter(log => log.symptoms)
    .map(log => ({
      date: log.date,
      pain: log.symptoms?.pain_level || 0,
      temp: log.symptoms?.temperature || 36.5
    }))

  const prompt = `
ìˆ˜ìˆ  í›„ íšŒë³µ ì¤‘ì¸ í™˜ìì˜ ì¦ìƒì„ ë¶„ì„í•˜ê³  ë¦¬ìŠ¤í¬ ìˆ˜ì¤€ì„ í‰ê°€í•˜ì„¸ìš”.

## í™˜ì ì •ë³´
- ìˆ˜ìˆ  ì¢…ë¥˜: ${profile.surgery_type}
- ìˆ˜ìˆ  í›„ ê²½ê³¼: D+${daysSinceSurgery}ì¼

## í˜„ì¬ ì¦ìƒ
- í†µì¦ ìˆ˜ì¹˜: ${symptoms.pain_level}/10
- ì²´ì˜¨: ${symptoms.temperature ? `${symptoms.temperature}Â°C` : 'ì¸¡ì •í•˜ì§€ ì•ŠìŒ'}
- ê°€ìŠ¤ ë°°ì¶œ: ${symptoms.gas_passed ? 'ì˜ˆ' : 'ì•„ë‹ˆì˜¤'}
${symptoms.other_symptoms ? `- ê¸°íƒ€ ì¦ìƒ: ${symptoms.other_symptoms}` : ''}

## ìµœê·¼ 7ì¼ ì¦ìƒ ì¶”ì´
${symptomTrend.length > 0
  ? symptomTrend.map(s => `${s.date}: í†µì¦ ${s.pain}/10, ì²´ì˜¨ ${s.temp}Â°C`).join('\n')
  : '(ìµœê·¼ ê¸°ë¡ ì—†ìŒ)'
}

## ë¦¬ìŠ¤í¬ í‰ê°€ ê¸°ì¤€

### High Risk (ì¦‰ì‹œ ë³‘ì› ë°©ë¬¸ í•„ìš”)
- ì²´ì˜¨ 38.5Â°C ì´ìƒ
- í†µì¦ ìˆ˜ì¹˜ 8 ì´ìƒì´ ì§€ì†ë¨
- ìˆ˜ìˆ  ë¶€ìœ„ ì‹¬í•œ ë¶€ì¢…, ë°œì , ê³ ë¦„
- ëŒ€ì¥/ìœ„ ìˆ˜ìˆ  í›„ 48ì‹œê°„ ì´ìƒ ê°€ìŠ¤ ë°°ì¶œ ì—†ìŒ
- í˜¸í¡ ê³¤ë€, ê°€ìŠ´ í†µì¦
- ì§€ì†ì ì¸ êµ¬í† 

### Medium Risk (24ì‹œê°„ ë‚´ ì˜ì‚¬ ìƒë‹´)
- ì²´ì˜¨ 37.5~38.5Â°C
- í†µì¦ ìˆ˜ì¹˜ 6~7ì´ ì§€ì†ë¨
- í†µì¦ ìˆ˜ì¹˜ê°€ ê¸‰ê²©íˆ ì¦ê°€ (2ì  ì´ìƒ)
- ì‹ì‚¬ í›„ ì§€ì†ì ì¸ ë¶ˆí¸ê°

### Low Risk (ì •ìƒ íšŒë³µ ë²”ìœ„)
- ìœ„ ì¡°ê±´ì— í•´ë‹¹í•˜ì§€ ì•ŠìŒ
- ê²½ë¯¸í•œ ë¶ˆí¸ê°ì€ ìˆ˜ìˆ  í›„ ì •ìƒ

## ì¶œë ¥ í˜•ì‹ (JSON)
\`\`\`json
{
  "riskLevel": "low|medium|high",
  "shouldContactDoctor": true|false,
  "recommendation": "í™˜ìê°€ ì·¨í•´ì•¼ í•  êµ¬ì²´ì ì¸ ì¡°ì¹˜ (2-3ë¬¸ì¥)",
  "explanation": "ì™œ ì´ëŸ° íŒë‹¨ì„ ë‚´ë ¸ëŠ”ì§€ ì‰½ê²Œ ì„¤ëª… (2-3ë¬¸ì¥)"
}
\`\`\`

**ì¤‘ìš”**: ì˜í•™ì  íŒë‹¨ì´ë¯€ë¡œ ë³´ìˆ˜ì ìœ¼ë¡œ í‰ê°€í•˜ì„¸ìš”. ì• ë§¤í•˜ë©´ medium ë˜ëŠ” highë¡œ ë¶„ë¥˜í•˜ì„¸ìš”.
  `.trim()

  const response = await openai.chat.completions.create({
    model: 'gpt-4o',
    messages: [{ role: 'user', content: prompt }],
    response_format: { type: 'json_object' },
    temperature: 0.3,  // ì˜ë£Œ íŒë‹¨ì€ ë‚®ì€ temperature
    max_tokens: 600,
  })

  const analysis = JSON.parse(response.choices[0].message.content || '{}')

  return {
    analysis,
    usage: response.usage
  }
}
```

---

## 8. ì£¼ê°„ ë¦¬í¬íŠ¸ ìë™ ìƒì„±

```typescript
// /lib/ai/report-generator.ts
import OpenAI from 'openai'
import { getDaysDifference } from '@/lib/profiling-engine'

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY })

export async function generateWeeklyReport(
  profile: UserProfile,
  weekLogs: LocalDailyLog[]
): Promise<{ report: string, usage: any }> {
  const daysSinceSurgery = getDaysDifference(profile.surgery_date, new Date())

  // í†µê³„ ê³„ì‚°
  const stats = {
    mealCompletion: calculateMealCompletion(weekLogs),
    exerciseCompletion: calculateExerciseCompletion(weekLogs),
    avgPain: calculateAvgPain(weekLogs),
    avgTemp: calculateAvgTemp(weekLogs),
  }

  const prompt = `
ë‹¤ìŒ ì£¼ê°„ íšŒë³µ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ í™˜ìì—ê²Œ ì¹œì ˆí•˜ê³  ê²©ë ¤í•˜ëŠ” í†¤ìœ¼ë¡œ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•˜ì„¸ìš”.

## í™˜ì ì •ë³´
- ìˆ˜ìˆ  ì¢…ë¥˜: ${profile.surgery_type}
- ìˆ˜ìˆ  í›„ ê²½ê³¼: D+${daysSinceSurgery}ì¼

## ì´ë²ˆ ì£¼ í†µê³„
- ì‹ì‚¬ ì™„ë£Œìœ¨: ${stats.mealCompletion}%
- ìš´ë™ ì™„ë£Œìœ¨: ${stats.exerciseCompletion}%
- í‰ê·  í†µì¦ ìˆ˜ì¹˜: ${stats.avgPain.toFixed(1)}/10
- í‰ê·  ì²´ì˜¨: ${stats.avgTemp.toFixed(1)}Â°C

## ì¼ë³„ ì„¸ë¶€ ë°ì´í„°
${weekLogs.map((log, idx) => `
${['ì›”', 'í™”', 'ìˆ˜', 'ëª©', 'ê¸ˆ', 'í† ', 'ì¼'][idx]}ìš”ì¼ (${log.date}):
- ì‹ì‚¬: ${Object.values(log.meals_completed || {}).filter(Boolean).length}/3 ì™„ë£Œ
- ìš´ë™: ${Object.values(log.exercises_completed || {}).filter(Boolean).length}ê°œ ì™„ë£Œ
- í†µì¦: ${log.symptoms?.pain_level || 0}/10
${log.notes ? `- ë©”ëª¨: ${log.notes}` : ''}
`).join('\n')}

## ë¦¬í¬íŠ¸ êµ¬ì„± (ë§ˆí¬ë‹¤ìš´ í˜•ì‹)

### ğŸ“Š í•œ ì£¼ ìš”ì•½
(2-3ë¬¸ì¥ìœ¼ë¡œ ì „ë°˜ì ì¸ íšŒë³µ ì§„í–‰ ìƒí™© ìš”ì•½)

### ğŸ‘ ì´ë²ˆ ì£¼ ì˜í•œ ì 
(2-3ê°œ í•­ëª©, êµ¬ì²´ì ìœ¼ë¡œ ì¹­ì°¬)
- ì˜ˆ: ì‹ì‚¬ë¥¼ ê·œì¹™ì ìœ¼ë¡œ í•˜ì…¨ë„¤ìš”! íŠ¹íˆ ìˆ˜ìš”ì¼ì—ëŠ” 3ë¼ë¥¼ ëª¨ë‘ ì™„ë£Œí•˜ì…¨ì–´ìš” ğŸ‰

### ğŸ’¡ ë‹¤ìŒ ì£¼ ê°œì„  ì œì•ˆ
(1-2ê°œ í•­ëª©, ë¶€ë“œëŸ½ê²Œ ì œì•ˆ)
- ì˜ˆ: ìš´ë™ì„ ì¡°ê¸ˆ ë” ëŠ˜ë ¤ë³´ì‹œë©´ ì–´ë–¨ê¹Œìš”? ì£¼ 3-4íšŒ ëª©í‘œë¡œ í•´ë³´ì„¸ìš” ğŸ˜Š

### ğŸ¯ ë‹¤ìŒ ì£¼ ëª©í‘œ
(ì‹¤ì²œ ê°€ëŠ¥í•œ êµ¬ì²´ì  ëª©í‘œ 1-2ê°œ)

### ğŸ’¬ ê²©ë ¤ ë©”ì‹œì§€
(ë”°ëœ»í•œ ë§ˆë¬´ë¦¬ 1-2ë¬¸ì¥)

**í†¤**: ì¹œê·¼í•˜ê³  ê²©ë ¤í•˜ëŠ” í†¤, ì´ëª¨ì§€ ì ì ˆíˆ í™œìš©, ì‰¬ìš´ ì–¸ì–´ ì‚¬ìš©
  `.trim()

  const response = await openai.chat.completions.create({
    model: 'gpt-4o',
    messages: [{ role: 'user', content: prompt }],
    temperature: 0.8,
    max_tokens: 1000,
  })

  return {
    report: response.choices[0].message.content || '',
    usage: response.usage
  }
}

function calculateMealCompletion(logs: LocalDailyLog[]): number {
  const total = logs.length * 3
  const completed = logs.reduce((sum, log) =>
    sum + Object.values(log.meals_completed || {}).filter(Boolean).length, 0
  )
  return Math.round((completed / total) * 100)
}

function calculateExerciseCompletion(logs: LocalDailyLog[]): number {
  const completed = logs.filter(log =>
    Object.values(log.exercises_completed || {}).some(Boolean)
  ).length
  return Math.round((completed / logs.length) * 100)
}

function calculateAvgPain(logs: LocalDailyLog[]): number {
  const validLogs = logs.filter(log => log.symptoms?.pain_level != null)
  if (validLogs.length === 0) return 0

  return validLogs.reduce((sum, log) =>
    sum + (log.symptoms?.pain_level || 0), 0
  ) / validLogs.length
}

function calculateAvgTemp(logs: LocalDailyLog[]): number {
  const validLogs = logs.filter(log => log.symptoms?.temperature != null)
  if (validLogs.length === 0) return 36.5

  return validLogs.reduce((sum, log) =>
    sum + (log.symptoms?.temperature || 36.5), 0
  ) / validLogs.length
}
```

---

## 9. ë¹„ìš© ìµœì í™”

### ìºì‹± ë° ìŠ¤ë§ˆíŠ¸ ë¼ìš°íŒ…

```typescript
// /lib/ai/cost-optimization.ts
import OpenAI from 'openai'

// ì‘ë‹µ ìºì‹œ (ê°„ë‹¨í•œ FAQ)
const responseCache = new Map<string, { response: string, timestamp: number }>()
const CACHE_TTL = 1000 * 60 * 60 // 1ì‹œê°„

export async function chatWithCaching(
  message: string,
  profile: UserProfile,
  conversationHistory: ChatMessage[]
): Promise<{ response: string, usage: any }> {
  // ì»¨í…ìŠ¤íŠ¸ ì—†ëŠ” ê°„ë‹¨í•œ ì§ˆë¬¸ì€ ìºì‹œ í™•ì¸
  if (conversationHistory.length === 0) {
    const cacheKey = `${profile.surgery_type}:${message.toLowerCase().trim()}`
    const cached = responseCache.get(cacheKey)

    if (cached && Date.now() - cached.timestamp < CACHE_TTL) {
      console.log('âœ… Cache hit:', cacheKey)
      return {
        response: cached.response,
        usage: { prompt_tokens: 0, completion_tokens: 0 }
      }
    }
  }

  const result = await chatWithAssistant(message, profile, conversationHistory)

  // ì¼ë°˜ì ì¸ ì§ˆë¬¸ë§Œ ìºì‹œ
  if (conversationHistory.length === 0) {
    const cacheKey = `${profile.surgery_type}:${message.toLowerCase().trim()}`
    responseCache.set(cacheKey, {
      response: result.response,
      timestamp: Date.now()
    })
  }

  return result
}

// ìŠ¤ë§ˆíŠ¸ ëª¨ë¸ ì„ íƒ
export function selectModel(message: string): 'gpt-4o' | 'gpt-4o-mini' {
  // ê°„ë‹¨í•œ ì§ˆë¬¸ íŒ¨í„´
  const simplePatterns = [
    /^(ì˜¤ëŠ˜|ë‚´ì¼|ì´ë²ˆì£¼)/,
    /ë¨¹ì–´ë„\s?(ë˜|ë¼)/,
    /^ì–¸ì œ/,
    /^ëª‡\s?(ì‹œ|ì¼|ë²ˆ)/,
    /^(ì˜ˆ|ì•„ë‹ˆì˜¤|ë„¤|ì‘|ã…‡ã…‡)/,
  ]

  const isSimple = simplePatterns.some(pattern => pattern.test(message.trim()))

  // ê°„ë‹¨í•œ ì§ˆë¬¸ì€ ì €ë ´í•œ mini ëª¨ë¸ ì‚¬ìš©
  // gpt-4o-mini: $0.15/1M input, $0.60/1M output (gpt-4oì˜ 1/30 ê°€ê²©)
  return isSimple ? 'gpt-4o-mini' : 'gpt-4o'
}

// í† í° ì‚¬ìš©ëŸ‰ ì¶”ì 
export async function trackTokenUsage(
  userId: string,
  endpoint: string,
  usage: { prompt_tokens: number, completion_tokens: number }
) {
  const cost = calculateCost(usage)

  await supabase.from('token_usage').insert({
    user_id: userId,
    date: new Date().toISOString().split('T')[0],
    endpoint,
    input_tokens: usage.prompt_tokens,
    output_tokens: usage.completion_tokens,
    cost
  })

  // ì¼ì¼ í•œë„ ì²´í¬ (ë¬´ë£Œ ì‚¬ìš©ìëŠ” $0.50/ì¼)
  const { data: todayUsage } = await supabase
    .from('token_usage')
    .select('cost')
    .eq('user_id', userId)
    .eq('date', new Date().toISOString().split('T')[0])

  const totalCost = todayUsage?.reduce((sum, u) => sum + u.cost, 0) || 0
  const dailyLimit = parseFloat(process.env.MAX_DAILY_AI_COST_PER_USER || '0.50')

  if (totalCost > dailyLimit) {
    throw new Error('ì¼ì¼ AI ì‚¬ìš© í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ë‚´ì¼ ë‹¤ì‹œ ì´ìš©í•´ì£¼ì„¸ìš”.')
  }

  return totalCost
}

function calculateCost(usage: { prompt_tokens: number, completion_tokens: number }): number {
  // GPT-4o ê°€ê²©: $5/1M input, $15/1M output
  const inputCost = (usage.prompt_tokens / 1_000_000) * 5
  const outputCost = (usage.completion_tokens / 1_000_000) * 15
  return inputCost + outputCost
}
```

---

## 10. ì•ˆì „ì¥ì¹˜ ë° ë³´ì•ˆ

```typescript
// /lib/ai/safety-guardrails.ts

// 1. í”„ë¡¬í”„íŠ¸ ì¸ì ì…˜ ë°©ì§€
export function sanitizeUserInput(input: string): string {
  // ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì¡°ì‘ ì‹œë„ ê°ì§€
  const dangerousPatterns = [
    /ignore\s+(previous|all)\s+instructions?/i,
    /you\s+are\s+now/i,
    /system\s*:/i,
    /assistant\s*:/i,
    /<\|.*?\|>/g,  // íŠ¹ìˆ˜ í† í°
    /\[INST\]/i,
    /\[\/INST\]/i,
  ]

  for (const pattern of dangerousPatterns) {
    if (pattern.test(input)) {
      console.warn('âš ï¸  Prompt injection attempt detected:', input)
      throw new Error('ë¶€ì ì ˆí•œ ì…ë ¥ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.')
    }
  }

  // ê¸¸ì´ ì œí•œ (í† í° ì ˆì•½)
  if (input.length > 1000) {
    return input.slice(0, 1000)
  }

  return input
}

// 2. ì‘ë‹µ ê²€ì¦
export function validateAIResponse(response: string): boolean {
  // ì˜ë£Œ ë©´ì±… ì¡°í•­ í™•ì¸
  const hasDisclaimer =
    response.includes('ì˜ì‚¬') ||
    response.includes('ì˜ë£Œì§„') ||
    response.includes('ë³‘ì›') ||
    response.includes('ìƒë‹´')

  if (!hasDisclaimer) {
    console.warn('âš ï¸  Missing medical disclaimer in response')
    // ë„ˆë¬´ ì—„ê²©í•˜ë©´ false positiveê°€ ë§ìœ¼ë¯€ë¡œ ê²½ê³ ë§Œ
  }

  // ìœ„í—˜í•œ ì¡°ì–¸ ê°ì§€
  const dangerousAdvice = [
    /ì•½\s*ì„?\s*(ëŠ|ì¤‘ë‹¨|ì•ˆ\s*ë¨¹)/i,
    /ë³‘ì›\s*(ì•ˆ?\s*ê°€ë„|ê°ˆ\s*í•„ìš”\s*ì—†)/i,
    /ì˜ì‚¬\s*(í•„ìš”\s*ì—†|ì•ˆ\s*ê°€ë„)/i,
  ]

  for (const pattern of dangerousAdvice) {
    if (pattern.test(response)) {
      console.error('âŒ Dangerous advice detected:', response)
      return false
    }
  }

  return true
}

// 3. Rate Limiting (Upstash Redis ì‚¬ìš©)
import { Ratelimit } from '@upstash/ratelimit'
import { Redis } from '@upstash/redis'

let ratelimit: Ratelimit | null = null

if (process.env.UPSTASH_REDIS_URL) {
  const redis = new Redis({
    url: process.env.UPSTASH_REDIS_URL,
    token: process.env.UPSTASH_REDIS_TOKEN!,
  })

  ratelimit = new Ratelimit({
    redis,
    limiter: Ratelimit.slidingWindow(20, '1 h'), // ì‹œê°„ë‹¹ 20íšŒ
    analytics: true,
  })
}

export async function checkRateLimit(userId: string): Promise<boolean> {
  if (!ratelimit) return true // Redis ì—†ìœ¼ë©´ ì œí•œ ì•ˆ í•¨

  const { success, limit, remaining } = await ratelimit.limit(userId)

  if (!success) {
    console.warn(`âš ï¸  Rate limit exceeded for user ${userId}`)
  }

  return success
}

// 4. ë¯¼ê° ì •ë³´ í•„í„°ë§
export function filterSensitiveInfo(text: string): string {
  return text
    .replace(/\d{6}-\d{7}/g, '******-*******')  // ì£¼ë¯¼ë²ˆí˜¸
    .replace(/01\d-\d{4}-\d{4}/g, '***-****-****')  // ì „í™”ë²ˆí˜¸
    .replace(/\d{4}-\d{4}-\d{4}-\d{4}/g, '****-****-****-****')  // ì¹´ë“œë²ˆí˜¸
}
```

---

## 11. ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

```typescript
// /lib/ai/monitoring.ts
import { supabase } from '@/lib/supabase-client'

export interface AIMetrics {
  endpoint: string
  model: string
  latency: number
  tokenUsage: {
    input: number
    output: number
  }
  cost: number
  success: boolean
  error?: string
}

export async function logAIMetrics(metrics: AIMetrics) {
  await supabase.from('ai_metrics').insert({
    endpoint: metrics.endpoint,
    model: metrics.model,
    latency_ms: metrics.latency,
    input_tokens: metrics.tokenUsage.input,
    output_tokens: metrics.tokenUsage.output,
    cost: metrics.cost,
    success: metrics.success,
    error_message: metrics.error,
  })

  // ì—ëŸ¬ìœ¨ ëª¨ë‹ˆí„°ë§
  if (!metrics.success) {
    console.error('[AI Error]', {
      endpoint: metrics.endpoint,
      model: metrics.model,
      error: metrics.error
    })

    // TODO: Slack/Discord ì•Œë¦¼ ë˜ëŠ” Sentry ì—°ë™
  }

  // ë¹„ìš© ì•Œë¦¼
  if (metrics.cost > 0.10) {
    console.warn('[High Cost]', {
      endpoint: metrics.endpoint,
      cost: metrics.cost,
      tokens: metrics.tokenUsage
    })
  }
}

// API í˜¸ì¶œ ë˜í¼ (ë©”íŠ¸ë¦­ ìë™ ìˆ˜ì§‘)
export async function withMetrics<T>(
  endpoint: string,
  model: string,
  fn: () => Promise<{ result: T, usage: any }>
): Promise<T> {
  const startTime = Date.now()
  let success = true
  let error: string | undefined
  let usage = { prompt_tokens: 0, completion_tokens: 0 }

  try {
    const { result, usage: tokenUsage } = await fn()
    usage = tokenUsage
    return result
  } catch (e: any) {
    success = false
    error = e.message
    throw e
  } finally {
    await logAIMetrics({
      endpoint,
      model,
      latency: Date.now() - startTime,
      tokenUsage: {
        input: usage.prompt_tokens,
        output: usage.completion_tokens
      },
      cost: calculateCost(usage),
      success,
      error
    })
  }
}

function calculateCost(usage: { prompt_tokens: number, completion_tokens: number }): number {
  const inputCost = (usage.prompt_tokens / 1_000_000) * 5
  const outputCost = (usage.completion_tokens / 1_000_000) * 15
  return inputCost + outputCost
}
```

---

## 12. API ì—”ë“œí¬ì¸íŠ¸

### AI ì±—ë´‡ API

```typescript
// /app/api/ai/chat/route.ts
import { NextRequest, NextResponse } from 'next/server'
import { chatWithCaching } from '@/lib/ai/cost-optimization'
import { checkRateLimit } from '@/lib/ai/safety-guardrails'
import { trackTokenUsage } from '@/lib/ai/cost-optimization'
import { withMetrics } from '@/lib/ai/monitoring'
import { supabase } from '@/lib/supabase-client'

export async function POST(request: NextRequest) {
  try {
    const { message, profileId, conversationHistory } = await request.json()

    // í”„ë¡œíŒŒì¼ ì¡°íšŒ
    const { data: profile, error: profileError } = await supabase
      .from('user_profiles')
      .select('*')
      .eq('id', profileId)
      .single()

    if (profileError || !profile) {
      return NextResponse.json(
        { error: 'Profile not found' },
        { status: 404 }
      )
    }

    // Rate limiting (ì‚¬ìš©ìë‹¹ ì‹œê°„ë‹¹ 20íšŒ)
    const userId = profile.user_id || 'anonymous'
    const canProceed = await checkRateLimit(userId)

    if (!canProceed) {
      return NextResponse.json(
        { error: 'ë„ˆë¬´ ë§ì€ ìš”ì²­ì…ë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.' },
        { status: 429 }
      )
    }

    // AI ì‘ë‹µ ìƒì„± (ë©”íŠ¸ë¦­ ìˆ˜ì§‘)
    const { response, usage } = await withMetrics(
      'chat',
      'gpt-4o',
      () => chatWithCaching(message, profile, conversationHistory)
    )

    // í† í° ì‚¬ìš©ëŸ‰ ì¶”ì 
    if (usage.prompt_tokens > 0) {
      await trackTokenUsage(userId, 'chat', usage)
    }

    // ëŒ€í™” íˆìŠ¤í† ë¦¬ ì €ì¥
    await supabase.from('chat_conversations').upsert({
      profile_id: profileId,
      messages: [
        ...conversationHistory,
        { role: 'user', content: message, timestamp: new Date() },
        { role: 'assistant', content: response, timestamp: new Date() }
      ],
      updated_at: new Date()
    })

    return NextResponse.json({ response })

  } catch (error: any) {
    console.error('Chat error:', error)

    if (error.message.includes('ì¼ì¼ AI ì‚¬ìš© í•œë„')) {
      return NextResponse.json(
        { error: error.message },
        { status: 429 }
      )
    }

    return NextResponse.json(
      { error: 'AI ì‘ë‹µ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.' },
      { status: 500 }
    )
  }
}
```

### AI ì‹ë‹¨ ìƒì„± API

```typescript
// /app/api/ai/generate-meal-plan/route.ts
import { NextRequest, NextResponse } from 'next/server'
import { generateAIMealPlan } from '@/lib/ai/meal-generator'
import { checkRateLimit } from '@/lib/ai/safety-guardrails'
import { trackTokenUsage } from '@/lib/ai/cost-optimization'
import { withMetrics } from '@/lib/ai/monitoring'
import { supabase } from '@/lib/supabase-client'

export async function POST(request: NextRequest) {
  try {
    const { profileId, preferences } = await request.json()

    const { data: profile } = await supabase
      .from('user_profiles')
      .select('*')
      .eq('id', profileId)
      .single()

    if (!profile) {
      return NextResponse.json({ error: 'Profile not found' }, { status: 404 })
    }

    const userId = profile.user_id || 'anonymous'
    const canProceed = await checkRateLimit(userId)

    if (!canProceed) {
      return NextResponse.json(
        { error: 'ë„ˆë¬´ ë§ì€ ìš”ì²­ì…ë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.' },
        { status: 429 }
      )
    }

    // AI ì‹ë‹¨ ìƒì„±
    const { mealPlan, usage } = await withMetrics(
      'meal_plan',
      'gpt-4o',
      () => generateAIMealPlan(profile, preferences)
    )

    await trackTokenUsage(userId, 'meal_plan', usage)

    return NextResponse.json({ mealPlan })

  } catch (error: any) {
    console.error('Meal plan generation error:', error)
    return NextResponse.json(
      { error: 'AI ì‹ë‹¨ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.' },
      { status: 500 }
    )
  }
}
```

### ì¦ìƒ ë¶„ì„ API

```typescript
// /app/api/ai/analyze-symptoms/route.ts
import { NextRequest, NextResponse } from 'next/server'
import { analyzeSymptoms } from '@/lib/ai/symptom-analyzer'
import { checkRateLimit } from '@/lib/ai/safety-guardrails'
import { trackTokenUsage } from '@/lib/ai/cost-optimization'
import { withMetrics } from '@/lib/ai/monitoring'
import { supabase } from '@/lib/supabase-client'

export async function POST(request: NextRequest) {
  try {
    const { profileId, symptoms } = await request.json()

    const { data: profile } = await supabase
      .from('user_profiles')
      .select('*')
      .eq('id', profileId)
      .single()

    if (!profile) {
      return NextResponse.json({ error: 'Profile not found' }, { status: 404 })
    }

    // ìµœê·¼ 7ì¼ ë¡œê·¸ ì¡°íšŒ
    const { data: recentLogs } = await supabase
      .from('daily_logs')
      .select('*')
      .eq('profile_id', profileId)
      .order('log_date', { ascending: false })
      .limit(7)

    const userId = profile.user_id || 'anonymous'
    const canProceed = await checkRateLimit(userId)

    if (!canProceed) {
      return NextResponse.json(
        { error: 'ë„ˆë¬´ ë§ì€ ìš”ì²­ì…ë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.' },
        { status: 429 }
      )
    }

    // AI ì¦ìƒ ë¶„ì„
    const { analysis, usage } = await withMetrics(
      'symptom_analysis',
      'gpt-4o',
      () => analyzeSymptoms(symptoms, profile, recentLogs || [])
    )

    await trackTokenUsage(userId, 'symptom_analysis', usage)

    // High riskì¸ ê²½ìš° ì•Œë¦¼ ì „ì†¡ (TODO)
    if (analysis.riskLevel === 'high') {
      console.warn('ğŸš¨ High risk detected for user:', userId)
      // TODO: í‘¸ì‹œ ì•Œë¦¼, ì´ë©”ì¼ ë“±
    }

    return NextResponse.json({ analysis })

  } catch (error: any) {
    console.error('Symptom analysis error:', error)
    return NextResponse.json(
      { error: 'ì¦ìƒ ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.' },
      { status: 500 }
    )
  }
}
```

### ì£¼ê°„ ë¦¬í¬íŠ¸ API

```typescript
// /app/api/ai/weekly-report/route.ts
import { NextRequest, NextResponse } from 'next/server'
import { generateWeeklyReport } from '@/lib/ai/report-generator'
import { trackTokenUsage } from '@/lib/ai/cost-optimization'
import { withMetrics } from '@/lib/ai/monitoring'
import { supabase } from '@/lib/supabase-client'

export async function POST(request: NextRequest) {
  try {
    const { profileId, weekStart } = await request.json()

    const { data: profile } = await supabase
      .from('user_profiles')
      .select('*')
      .eq('id', profileId)
      .single()

    if (!profile) {
      return NextResponse.json({ error: 'Profile not found' }, { status: 404 })
    }

    // í•´ë‹¹ ì£¼ì˜ ë¡œê·¸ ì¡°íšŒ
    const weekEnd = new Date(weekStart)
    weekEnd.setDate(weekEnd.getDate() + 7)

    const { data: weekLogs } = await supabase
      .from('daily_logs')
      .select('*')
      .eq('profile_id', profileId)
      .gte('log_date', weekStart)
      .lt('log_date', weekEnd.toISOString())
      .order('log_date', { ascending: true })

    if (!weekLogs || weekLogs.length === 0) {
      return NextResponse.json(
        { error: 'ì´ë²ˆ ì£¼ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.' },
        { status: 404 }
      )
    }

    // AI ë¦¬í¬íŠ¸ ìƒì„±
    const { report, usage } = await withMetrics(
      'weekly_report',
      'gpt-4o',
      () => generateWeeklyReport(profile, weekLogs)
    )

    const userId = profile.user_id || 'anonymous'
    await trackTokenUsage(userId, 'weekly_report', usage)

    return NextResponse.json({ report })

  } catch (error: any) {
    console.error('Weekly report generation error:', error)
    return NextResponse.json(
      { error: 'ì£¼ê°„ ë¦¬í¬íŠ¸ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.' },
      { status: 500 }
    )
  }
}
```

---

## 13. í™˜ê²½ ë³€ìˆ˜

```bash
# .env.local

# ê¸°ì¡´ í™˜ê²½ ë³€ìˆ˜
NEXT_PUBLIC_SUPABASE_URL=https://xxx.supabase.co
NEXT_PUBLIC_SUPABASE_ANON_KEY=eyJxxx...
SUPABASE_SERVICE_ROLE_KEY=eyJxxx...
NEXT_PUBLIC_APP_URL=https://recovery-manager.vercel.app

# OpenAI
OPENAI_API_KEY=sk-proj-xxx...
NEXT_PUBLIC_ENABLE_AI_CHAT=true

# Rate Limiting (ì„ íƒì )
UPSTASH_REDIS_URL=https://xxx.upstash.io
UPSTASH_REDIS_TOKEN=xxx

# ë¹„ìš© ì œí•œ
MAX_DAILY_AI_COST_PER_USER=0.50  # USD
```

---

## 14. ì—…ë°ì´íŠ¸ëœ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
post-surgery-recovery-manager/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ ai/
â”‚   â”‚   â”‚   â”œâ”€â”€ chat/route.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ generate-meal-plan/route.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ analyze-symptoms/route.ts
â”‚   â”‚   â”‚   â””â”€â”€ weekly-report/route.ts
â”‚   â”‚   â”œâ”€â”€ meal-plan/route.ts
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ dashboard/page.tsx  (AI ì±—ë´‡ ì¶”ê°€)
â”‚   â””â”€â”€ ...
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ AIChatbot.tsx
â”‚   â”œâ”€â”€ AIMealGenerator.tsx
â”‚   â”œâ”€â”€ FloatingChatButton.tsx
â”‚   â””â”€â”€ ...
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ ai/
â”‚   â”‚   â”œâ”€â”€ embeddings.ts
â”‚   â”‚   â”œâ”€â”€ rag-search.ts
â”‚   â”‚   â”œâ”€â”€ chat-assistant.ts
â”‚   â”‚   â”œâ”€â”€ meal-generator.ts
â”‚   â”‚   â”œâ”€â”€ symptom-analyzer.ts
â”‚   â”‚   â”œâ”€â”€ report-generator.ts
â”‚   â”‚   â”œâ”€â”€ cost-optimization.ts
â”‚   â”‚   â”œâ”€â”€ safety-guardrails.ts
â”‚   â”‚   â””â”€â”€ monitoring.ts
â”‚   â”œâ”€â”€ profiling-engine.ts
â”‚   â”œâ”€â”€ meal-planner.ts
â”‚   â””â”€â”€ ...
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ index-knowledge-base.ts
â”œâ”€â”€ supabase/
â”‚   â””â”€â”€ migrations/
â”‚       â”œâ”€â”€ 001_initial_schema.sql
â”‚       â”œâ”€â”€ 002_vector_search.sql
â”‚       â””â”€â”€ 003_ai_tables.sql
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ protocols/surgery-protocols.ts
â”‚   â”œâ”€â”€ meals/meal-database.json
â”‚   â””â”€â”€ exercises/exercise-database.json
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ plans/
â”‚       â”œâ”€â”€ 2026-01-24-recovery-manager-design.md
â”‚       â””â”€â”€ 2026-01-24-llm-integration-design.md
â”œâ”€â”€ .env.local
â”œâ”€â”€ package.json
â””â”€â”€ ...
```

---

## 15. ë¹„ìš© ë¶„ì„

### ì›”ê°„ ë¹„ìš© ì¶”ì • (ì‚¬ìš©ì 1,000ëª…)

**ì‚¬ìš© íŒ¨í„´ ê°€ì •**
- AI ì±—ë´‡: ì‚¬ìš©ìë‹¹ í‰ê·  10íšŒ/ì¼ Ã— í‰ê·  300 í† í°/ëŒ€í™”
- ì‹ë‹¨ ìƒì„±: ì£¼ 1íšŒ Ã— 2,000 í† í°
- ì¦ìƒ ë¶„ì„: ì¼ 1íšŒ Ã— 500 í† í°
- ì£¼ê°„ ë¦¬í¬íŠ¸: ì£¼ 1íšŒ Ã— 1,000 í† í°

**í† í° ì‚¬ìš©ëŸ‰ (ì‚¬ìš©ìë‹¹/ì›”)**
- ì±—ë´‡: 10íšŒ/ì¼ Ã— 30ì¼ Ã— 300í† í° = 90,000 í† í°
- ì‹ë‹¨: 4íšŒ/ì›” Ã— 2,000í† í° = 8,000 í† í°
- ì¦ìƒ: 30íšŒ/ì›” Ã— 500í† í° = 15,000 í† í°
- ë¦¬í¬íŠ¸: 4íšŒ/ì›” Ã— 1,000í† í° = 4,000 í† í°

**ì´**: ~117,000 í† í°/ì‚¬ìš©ì/ì›” (input + output í•©ì‚°)

**ë¹„ìš© ê³„ì‚° (GPT-4o ê¸°ì¤€)**
- Input í† í° ë¹„ìš©: 60,000 Ã— $5/1M = $0.30
- Output í† í° ë¹„ìš©: 57,000 Ã— $15/1M = $0.86
- **ì‚¬ìš©ìë‹¹ ì›” ë¹„ìš©**: $1.16

**1,000ëª… ì›” ë¹„ìš©**: $1,160

**ìµœì í™” í›„ (ìºì‹± 50% + mini ëª¨ë¸ 30%)**
- ìºì‹±ìœ¼ë¡œ ì¤‘ë³µ ì§ˆë¬¸ 50% ì ˆê°: -$580
- ê°„ë‹¨í•œ ì§ˆë¬¸ gpt-4o-mini ì‚¬ìš© (1/30 ê°€ê²©): -$200
- **ìµœì í™” ì›” ë¹„ìš©**: ~$380

### Supabase ë¹„ìš©
- Pro í”Œëœ: $25/ì›”
  - 8GB ë°ì´í„°ë² ì´ìŠ¤
  - 100K MAU
  - pgvector í¬í•¨

### ì´ ì˜ˆìƒ ë¹„ìš©
- **ìµœì í™” ì „**: $1,185/ì›”
- **ìµœì í™” í›„**: $405/ì›”

---

## 16. êµ¬í˜„ ìš°ì„ ìˆœìœ„

### Phase 1: ì½”ì–´ AI ê¸°ëŠ¥ (2-3ì£¼)
1. âœ… ë²¡í„° DB ì„¤ì • ë° ì§€ì‹ ë² ì´ìŠ¤ ì¸ë±ì‹±
2. âœ… RAG ê²€ìƒ‰ ë¡œì§ êµ¬í˜„
3. âœ… AI ì±—ë´‡ êµ¬í˜„
4. âœ… ê¸°ë³¸ ì•ˆì „ì¥ì¹˜ (í”„ë¡¬í”„íŠ¸ ì¸ì ì…˜, ì‘ë‹µ ê²€ì¦)

### Phase 2: ê³ ê¸‰ ê¸°ëŠ¥ (2ì£¼)
5. âœ… AI ì‹ë‹¨ ìƒì„±
6. âœ… ì¦ìƒ ë¶„ì„ ë° ë¦¬ìŠ¤í¬ í‰ê°€
7. âœ… ì£¼ê°„ ë¦¬í¬íŠ¸ ìë™ ìƒì„±

### Phase 3: ìµœì í™” ë° ëª¨ë‹ˆí„°ë§ (1-2ì£¼)
8. âœ… ë¹„ìš© ìµœì í™” (ìºì‹±, ìŠ¤ë§ˆíŠ¸ ë¼ìš°íŒ…)
9. âœ… ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë° ë©”íŠ¸ë¦­ ìˆ˜ì§‘
10. âœ… Rate limiting

### Phase 4: í”„ë¡œë•ì…˜ ì¤€ë¹„ (1ì£¼)
11. ì—ëŸ¬ í•¸ë“¤ë§ ê°•í™”
12. ì‚¬ìš©ì í”¼ë“œë°± ìˆ˜ì§‘ (ğŸ‘/ğŸ‘ ë²„íŠ¼)
13. A/B í…ŒìŠ¤íŠ¸ (ë£° ê¸°ë°˜ vs AI ê¸°ë°˜)

---

## 17. ì„±ê³µ ì§€í‘œ (KPI)

### AI ê¸°ëŠ¥ ì„±ëŠ¥
- **ì±—ë´‡ ì‘ë‹µ ì‹œê°„**: í‰ê·  3ì´ˆ ì´ë‚´
- **ì‘ë‹µ ì •í™•ë„**: ì‚¬ìš©ì ë§Œì¡±ë„ 80% ì´ìƒ (ğŸ‘/ğŸ‘ ë²„íŠ¼)
- **ì¼ì¼ í™œì„± ì±—ë´‡ ì‚¬ìš©ì**: ì „ì²´ ì‚¬ìš©ìì˜ 40% ì´ìƒ

### ë¹„ìš© íš¨ìœ¨ì„±
- **ì‚¬ìš©ìë‹¹ ì›” AI ë¹„ìš©**: $0.50 ì´í•˜ ìœ ì§€
- **ìºì‹œ íˆíŠ¸ìœ¨**: 30% ì´ìƒ
- **í† í° ì‚¬ìš©ëŸ‰ ê°ì†Œ**: ìµœì í™”ë¡œ 40% ì ˆê°

### ì‚¬ìš©ì ì°¸ì—¬ë„
- **AI ì‹ë‹¨ ì±„íƒë¥ **: ìƒì„±ëœ ì‹ë‹¨ì˜ 60% ì´ìƒ ì‚¬ìš©
- **ì¦ìƒ ë¶„ì„ ì‚¬ìš©**: ì£¼ 1íšŒ ì´ìƒ
- **ì£¼ê°„ ë¦¬í¬íŠ¸ ì—´ëŒë¥ **: 80% ì´ìƒ

---

**ë¬¸ì„œ ë**
